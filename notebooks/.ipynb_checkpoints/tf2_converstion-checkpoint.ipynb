{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../MaskRCNN/')\n",
    "import itertools\n",
    "import numpy as np\n",
    "import shutil\n",
    "import cv2\n",
    "import six\n",
    "assert six.PY3, \"FasterRCNN requires Python 3!\"\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tqdm\n",
    "import time\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "import tensorpack_viz as tpviz\n",
    "from tensorpack_tfutils import get_tf_version_tuple, get_model_loader\n",
    "from tensorpack_utils import fix_rng_seed\n",
    "from tensorpack_input_source import QueueInput\n",
    "from tensorpack_train import TrainConfig\n",
    "from tensorpack_interface import launch_train_with_config\n",
    "from tensorpack_callbacks import PeriodicCallback, EnableCallbackIf, ModelSaver,\\\n",
    "                                 GraphProfiler, PeakMemoryTracker, EstimatedTimeLeft, SessionRunTimeout, \\\n",
    "                                 MovingAverageSummary, ProgressBar, MergeAllSummaries, RunUpdateOps, ScheduledHyperParamSetter\n",
    "import tensorpack_logger as logger\n",
    "\n",
    "\n",
    "from dataset import DetectionDataset\n",
    "from config import finalize_configs, config as cfg\n",
    "from data import get_eval_dataflow, get_train_dataflow, get_batch_train_dataflow\n",
    "from eval import DetectionResult, predict_image, multithread_predict_dataflow, EvalCallback\n",
    "from viz import draw_annotation, draw_final_outputs, draw_predictions, draw_proposal_recall\n",
    "from performance import ThroughputTracker, humanize_float\n",
    "from model.generalized_rcnn import ResNetFPNModel\n",
    "import horovod.tensorflow as hvd\n",
    "\n",
    "config = ['MODE_MASK=True',\n",
    "'MODE_FPN=True',\n",
    "'DATA.BASEDIR=/workspace/shared_workspace/data/coco/coco/',\n",
    "'DATA.TRAIN=[\"train2017\"]',\n",
    "'DATA.VAL=(\"val2017\",)',\n",
    "'TRAIN.BATCH_SIZE_PER_GPU=4',\n",
    "'TRAIN.LR_EPOCH_SCHEDULE=[(8, 0.1), (10, 0.01), (12, None)]',\n",
    "'TRAIN.EVAL_PERIOD=24',\n",
    "'TRAIN.BACKBONE_NCHW=False',\n",
    "'TRAIN.FPN_NCHW=False',\n",
    "'TRAIN.RPN_NCHW=False',\n",
    "'TRAIN.MASK_NCHW=False',\n",
    "'RPN.TOPK_PER_IMAGE=True',\n",
    "'PREPROC.PREDEFINED_PADDING=False',\n",
    "'BACKBONE.WEIGHTS=/workspace/shared_workspace/data/coco/pretrained-models/ImageNet-R50-AlignPadding.npz',\n",
    "'BACKBONE.NORM=FreezeBN',\n",
    "'TRAIN.WARMUP_INIT_LR=0.000416666666667',\n",
    "'FRCNN.BBOX_REG_WEIGHTS=[20., 20., 10., 10.]',\n",
    "'TRAINER=horovod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.update_args(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = ResNetFPNModel(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dataset.DetectionDataset at 0x7f21a33f8dd8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DetectionDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_horovod = cfg.TRAINER == 'horovod'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvd.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0818 12:55:09 @config.py:264]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m It's not recommended to use horovod for single-machine training. Replicated trainer is more stable and has the same efficiency.\n",
      "\u001b[32m[0818 12:55:09 @config.py:285]\u001b[0m Config: ------------------------------------------\n",
      "{'BACKBONE': {'FREEZE_AFFINE': False,\n",
      "              'FREEZE_AT': 2,\n",
      "              'NORM': 'FreezeBN',\n",
      "              'RESNET_NUM_BLOCKS': [3, 4, 6, 3],\n",
      "              'STRIDE_1X1': False,\n",
      "              'TF_PAD_MODE': False,\n",
      "              'WEIGHTS': '/workspace/shared_workspace/data/coco/pretrained-models/ImageNet-R50-AlignPadding.npz'},\n",
      " 'DATA': {'BASEDIR': '/workspace/shared_workspace/data/coco/coco/',\n",
      "          'CLASS_NAMES': ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
      "                          'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
      "                          'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
      "                          'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag',\n",
      "                          'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite',\n",
      "                          'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
      "                          'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon',\n",
      "                          'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot',\n",
      "                          'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant',\n",
      "                          'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
      "                          'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',\n",
      "                          'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
      "                          'hair drier', 'toothbrush'],\n",
      "          'NUM_CATEGORY': 80,\n",
      "          'NUM_CLASS': 81,\n",
      "          'TRAIN': ['train2017'],\n",
      "          'VAL': ('val2017',)},\n",
      " 'FPN': {'ANCHOR_STRIDES': (4, 8, 16, 32, 64),\n",
      "         'BOXCLASS_CONV_HEAD_DIM': 256,\n",
      "         'BOXCLASS_FC_HEAD_DIM': 1024,\n",
      "         'BOXCLASS_HEAD_FUNC': 'boxclass_2fc_head',\n",
      "         'MRCNN_HEAD_FUNC': 'maskrcnn_up4conv_head',\n",
      "         'NORM': 'None',\n",
      "         'NUM_CHANNEL': 256,\n",
      "         'PROPOSAL_MODE': 'Level',\n",
      "         'RESOLUTION_REQUIREMENT': 32},\n",
      " 'FRCNN': {'BATCH_PER_IM': 512,\n",
      "           'BBOX_REG_WEIGHTS': [20.0, 20.0, 10.0, 10.0],\n",
      "           'FG_RATIO': 0.25,\n",
      "           'FG_THRESH': 0.5},\n",
      " 'MODE_FPN': True,\n",
      " 'MODE_MASK': True,\n",
      " 'MRCNN': {'HEAD_DIM': 256},\n",
      " 'PREPROC': {'MAX_SIZE': 1344.0,\n",
      "             'PADDING_SHAPES': [(800, 1000), (800, 1200), (800, 1350)],\n",
      "             'PIXEL_MEAN': [123.675, 116.28, 103.53],\n",
      "             'PIXEL_STD': [58.395, 57.12, 57.375],\n",
      "             'PREDEFINED_PADDING': False,\n",
      "             'TEST_SHORT_EDGE_SIZE': 800,\n",
      "             'TRAIN_SHORT_EDGE_SIZE': [800, 800]},\n",
      " 'RPN': {'ANCHOR_RATIOS': (0.5, 1.0, 2.0),\n",
      "         'ANCHOR_SIZES': (32, 64, 128, 256, 512),\n",
      "         'ANCHOR_STRIDE': 16,\n",
      "         'BATCH_PER_IM': 256,\n",
      "         'CROWD_OVERLAP_THRESH': 9.99,\n",
      "         'FG_RATIO': 0.5,\n",
      "         'HEAD_DIM': 1024,\n",
      "         'MIN_SIZE': 0.1,\n",
      "         'NEGATIVE_ANCHOR_THRESH': 0.3,\n",
      "         'NUM_ANCHOR': 15,\n",
      "         'POSITIVE_ANCHOR_THRESH': 0.7,\n",
      "         'PROPOSAL_NMS_THRESH': 0.7,\n",
      "         'SLOW_ACCURATE_MASK': True,\n",
      "         'TEST_PER_LEVEL_NMS_TOPK': 1000,\n",
      "         'TEST_POST_NMS_TOPK': 1000,\n",
      "         'TEST_PRE_NMS_TOPK': 6000,\n",
      "         'TOPK_PER_IMAGE': True,\n",
      "         'TRAIN_PER_LEVEL_NMS_TOPK': 2000,\n",
      "         'TRAIN_POST_NMS_TOPK': 2000,\n",
      "         'TRAIN_PRE_NMS_TOPK': 12000,\n",
      "         'UNQUANTIZED_ANCHOR': True},\n",
      " 'TEST': {'BOX_TARGET': 0.377,\n",
      "          'FRCNN_NMS_THRESH': 0.5,\n",
      "          'MASK_TARGET': 0.339,\n",
      "          'RESULTS_PER_IM': 100,\n",
      "          'RESULT_SCORE_THRESH': 0.05,\n",
      "          'RESULT_SCORE_THRESH_VIS': 0.3},\n",
      " 'TRAIN': {'BACKBONE_NCHW': False,\n",
      "           'BASE_LR': 0.00125,\n",
      "           'BATCH_SIZE_PER_GPU': 4,\n",
      "           'EVAL_PERIOD': 24,\n",
      "           'FPN_NCHW': False,\n",
      "           'GRADIENT_CLIP': 0,\n",
      "           'LR_EPOCH_SCHEDULE': [(8, 0.1), (10, 0.01), (12, None)],\n",
      "           'MASK_NCHW': False,\n",
      "           'NUM_GPUS': 1,\n",
      "           'RPN_NCHW': False,\n",
      "           'SEED': 1234,\n",
      "           'SHOULD_STOP': False,\n",
      "           'STARTING_EPOCH': 1,\n",
      "           'WARMUP_INIT_LR': 0.000416666666667,\n",
      "           'WARMUP_STEPS': 1000,\n",
      "           'WEIGHT_DECAY': 0.0001},\n",
      " 'TRAINER': 'horovod'}\n"
     ]
    }
   ],
   "source": [
    "finalize_configs(is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.TRAIN.EVAL_PERIOD = 1\n",
    "tf.set_random_seed(cfg.TRAIN.SEED)\n",
    "fix_rng_seed(cfg.TRAIN.SEED*hvd.rank())\n",
    "np.random.seed(cfg.TRAIN.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_per_epoch = 120000\n",
    "images_per_step = cfg.TRAIN.NUM_GPUS * cfg.TRAIN.BATCH_SIZE_PER_GPU\n",
    "steps_per_epoch = images_per_epoch // images_per_step\n",
    "batch_size_lr_factor = images_per_step # The LR is defined for bs=1 and then scaled linearly with the batch size\n",
    "base_lr_adjusted_for_bs = cfg.TRAIN.BASE_LR * batch_size_lr_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup LR schedule is step based\n",
    "warmup_start_step = 0\n",
    "warmup_end_step = cfg.TRAIN.WARMUP_STEPS\n",
    "warmup_start_lr = cfg.TRAIN.WARMUP_INIT_LR*8\n",
    "warmup_end_lr = base_lr_adjusted_for_bs\n",
    "warmup_schedule = [(warmup_start_step, warmup_start_lr), (warmup_end_step, warmup_end_lr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_end_epoch = cfg.TRAIN.WARMUP_STEPS * 1. / steps_per_epoch\n",
    "training_start_epoch = int(warmup_end_epoch + 0.5)\n",
    "lr_schedule = [(training_start_epoch, base_lr_adjusted_for_bs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = None\n",
    "for epoch, scheduled_lr_multiplier in cfg.TRAIN.LR_EPOCH_SCHEDULE:\n",
    "    if scheduled_lr_multiplier is None:\n",
    "        max_epoch = epoch # Training end is indicated by a lr_multiplier of None\n",
    "        break\n",
    "\n",
    "    absolute_lr = base_lr_adjusted_for_bs * scheduled_lr_multiplier\n",
    "    lr_schedule.append((epoch, absolute_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In train dataflow\n",
      "loading annotations into memory...\n",
      "Done (t=14.60s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[0818 12:55:24 @dataset.py:50]\u001b[0m Instances loaded from /workspace/shared_workspace/data/coco/coco/annotations/instances_train2017.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118287/118287 [00:17<00:00, 6772.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0818 12:55:42 @tensorpack_utils.py:349]\u001b[0m Load Load annotations for train2017 finished, time:17.5508sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading roidbs\n",
      "\u001b[32m[0818 12:55:44 @data.py:618]\u001b[0m Filtered 1021 images which contain no non-crowd groudtruth boxes. Total #images for training: 117266\n",
      "Batching roidbs\n",
      "Done batching roidbs\n"
     ]
    }
   ],
   "source": [
    "train_dataflow = get_batch_train_dataflow(cfg.TRAIN.BATCH_SIZE_PER_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = '/workspace/shared_workspace/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    PeriodicCallback(\n",
    "        ModelSaver(max_to_keep=10, keep_checkpoint_every_n_hours=1),\n",
    "        every_k_epochs=20),\n",
    "    # linear warmup\n",
    "    ScheduledHyperParamSetter(\n",
    "        'learning_rate', warmup_schedule, interp='linear', step_based=True),\n",
    "    ScheduledHyperParamSetter('learning_rate', lr_schedule),\n",
    "    PeakMemoryTracker(),\n",
    "    EstimatedTimeLeft(median=True),\n",
    "    SessionRunTimeout(60000).set_chief_only(True),   # 1 minute timeout\n",
    "]\n",
    "\n",
    "callbacks.extend([\n",
    "    EvalCallback(dataset, *MODEL.get_inference_tensor_names(), logdir, 1, a_sync=True) #cfg.TRAIN.BATCH_SIZE_PER_GPU)\n",
    "    for dataset in cfg.DATA.VAL\n",
    "])\n",
    "\n",
    "\n",
    "callbacks.append(ThroughputTracker(cfg.TRAIN.BATCH_SIZE_PER_GPU*cfg.TRAIN.NUM_GPUS,\n",
    "                                   images_per_epoch,\n",
    "                                   trigger_every_n_steps=2000,\n",
    "                                   log_fn=logger.info))\n",
    "\n",
    "# create profiler callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
