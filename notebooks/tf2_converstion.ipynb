{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../MaskRCNN/')\n",
    "import itertools\n",
    "import numpy as np\n",
    "import shutil\n",
    "import cv2\n",
    "import six\n",
    "assert six.PY3, \"FasterRCNN requires Python 3!\"\n",
    "import tensorflow.compat.v1 as tf\n",
    "'''from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)'''\n",
    "tf.disable_eager_execution()\n",
    "import tqdm\n",
    "import time\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "import tensorpack_viz as tpviz\n",
    "from tensorpack_tfutils import get_tf_version_tuple, get_model_loader\n",
    "from tensorpack_utils import fix_rng_seed\n",
    "from tensorpack_input_source import QueueInput\n",
    "from tensorpack_train import TrainConfig\n",
    "from tensorpack_interface import launch_train_with_config\n",
    "from tensorpack_callbacks import PeriodicCallback, EnableCallbackIf, ModelSaver,\\\n",
    "                                 GraphProfiler, PeakMemoryTracker, EstimatedTimeLeft, SessionRunTimeout, \\\n",
    "                                 MovingAverageSummary, ProgressBar, MergeAllSummaries, RunUpdateOps, ScheduledHyperParamSetter\n",
    "import tensorpack_logger as logger\n",
    "\n",
    "\n",
    "from dataset import DetectionDataset\n",
    "from config import finalize_configs, config as cfg\n",
    "from data import get_eval_dataflow, get_train_dataflow, get_batch_train_dataflow\n",
    "from eval import DetectionResult, predict_image, multithread_predict_dataflow, EvalCallback\n",
    "from viz import draw_annotation, draw_final_outputs, draw_predictions, draw_proposal_recall\n",
    "from performance import ThroughputTracker, humanize_float\n",
    "from model.generalized_rcnn import ResNetFPNModel\n",
    "import horovod.tensorflow as hvd\n",
    "\n",
    "config = ['MODE_MASK=True',\n",
    "'MODE_FPN=True',\n",
    "'DATA.BASEDIR=/workspace/shared_workspace/data/coco/coco/',\n",
    "'DATA.TRAIN=[\"train2017\"]',\n",
    "'DATA.VAL=(\"val2017\",)',\n",
    "'TRAIN.BATCH_SIZE_PER_GPU=4',\n",
    "'TRAIN.LR_EPOCH_SCHEDULE=[(8, 0.1), (10, 0.01), (12, None)]',\n",
    "'TRAIN.EVAL_PERIOD=24',\n",
    "'TRAIN.BACKBONE_NCHW=False',\n",
    "'TRAIN.FPN_NCHW=False',\n",
    "'TRAIN.RPN_NCHW=False',\n",
    "'TRAIN.MASK_NCHW=False',\n",
    "'RPN.TOPK_PER_IMAGE=True',\n",
    "'PREPROC.PREDEFINED_PADDING=False',\n",
    "'BACKBONE.WEIGHTS=/workspace/shared_workspace/data/coco/pretrained-models/ImageNet-R50-AlignPadding.npz',\n",
    "'BACKBONE.NORM=FreezeBN',\n",
    "'TRAIN.WARMUP_INIT_LR=0.000416666666667',\n",
    "'FRCNN.BBOX_REG_WEIGHTS=[20., 20., 10., 10.]',\n",
    "'TRAINER=horovod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TENSORPACK_FP16']='1'\n",
    "os.environ['TF_CUDNN_USE_AUTOTUNE']='0'\n",
    "os.environ['TF_ENABLE_NHWC']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.update_args(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = ResNetFPNModel(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dataset.DetectionDataset at 0x7f5cc3dee860>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DetectionDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_horovod = cfg.TRAINER == 'horovod'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvd.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0819 15:29:02 @config.py:285]\u001b[0m Config: ------------------------------------------\n",
      "{'BACKBONE': {'FREEZE_AFFINE': False,\n",
      "              'FREEZE_AT': 2,\n",
      "              'NORM': 'FreezeBN',\n",
      "              'RESNET_NUM_BLOCKS': [3, 4, 6, 3],\n",
      "              'STRIDE_1X1': False,\n",
      "              'TF_PAD_MODE': False,\n",
      "              'WEIGHTS': '/workspace/shared_workspace/data/coco/pretrained-models/ImageNet-R50-AlignPadding.npz'},\n",
      " 'DATA': {'BASEDIR': '/workspace/shared_workspace/data/coco/coco/',\n",
      "          'CLASS_NAMES': ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
      "                          'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
      "                          'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
      "                          'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag',\n",
      "                          'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite',\n",
      "                          'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
      "                          'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon',\n",
      "                          'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot',\n",
      "                          'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant',\n",
      "                          'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
      "                          'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',\n",
      "                          'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
      "                          'hair drier', 'toothbrush'],\n",
      "          'NUM_CATEGORY': 80,\n",
      "          'NUM_CLASS': 81,\n",
      "          'TRAIN': ['train2017'],\n",
      "          'VAL': ('val2017',)},\n",
      " 'FPN': {'ANCHOR_STRIDES': (4, 8, 16, 32, 64),\n",
      "         'BOXCLASS_CONV_HEAD_DIM': 256,\n",
      "         'BOXCLASS_FC_HEAD_DIM': 1024,\n",
      "         'BOXCLASS_HEAD_FUNC': 'boxclass_2fc_head',\n",
      "         'MRCNN_HEAD_FUNC': 'maskrcnn_up4conv_head',\n",
      "         'NORM': 'None',\n",
      "         'NUM_CHANNEL': 256,\n",
      "         'PROPOSAL_MODE': 'Level',\n",
      "         'RESOLUTION_REQUIREMENT': 32},\n",
      " 'FRCNN': {'BATCH_PER_IM': 512,\n",
      "           'BBOX_REG_WEIGHTS': [20.0, 20.0, 10.0, 10.0],\n",
      "           'FG_RATIO': 0.25,\n",
      "           'FG_THRESH': 0.5},\n",
      " 'MODE_FPN': True,\n",
      " 'MODE_MASK': True,\n",
      " 'MRCNN': {'HEAD_DIM': 256},\n",
      " 'PREPROC': {'MAX_SIZE': 1344.0,\n",
      "             'PADDING_SHAPES': [(800, 1000), (800, 1200), (800, 1350)],\n",
      "             'PIXEL_MEAN': [123.675, 116.28, 103.53],\n",
      "             'PIXEL_STD': [58.395, 57.12, 57.375],\n",
      "             'PREDEFINED_PADDING': False,\n",
      "             'TEST_SHORT_EDGE_SIZE': 800,\n",
      "             'TRAIN_SHORT_EDGE_SIZE': [800, 800]},\n",
      " 'RPN': {'ANCHOR_RATIOS': (0.5, 1.0, 2.0),\n",
      "         'ANCHOR_SIZES': (32, 64, 128, 256, 512),\n",
      "         'ANCHOR_STRIDE': 16,\n",
      "         'BATCH_PER_IM': 256,\n",
      "         'CROWD_OVERLAP_THRESH': 9.99,\n",
      "         'FG_RATIO': 0.5,\n",
      "         'HEAD_DIM': 1024,\n",
      "         'MIN_SIZE': 0.1,\n",
      "         'NEGATIVE_ANCHOR_THRESH': 0.3,\n",
      "         'NUM_ANCHOR': 15,\n",
      "         'POSITIVE_ANCHOR_THRESH': 0.7,\n",
      "         'PROPOSAL_NMS_THRESH': 0.7,\n",
      "         'SLOW_ACCURATE_MASK': True,\n",
      "         'TEST_PER_LEVEL_NMS_TOPK': 1000,\n",
      "         'TEST_POST_NMS_TOPK': 1000,\n",
      "         'TEST_PRE_NMS_TOPK': 6000,\n",
      "         'TOPK_PER_IMAGE': True,\n",
      "         'TRAIN_PER_LEVEL_NMS_TOPK': 2000,\n",
      "         'TRAIN_POST_NMS_TOPK': 2000,\n",
      "         'TRAIN_PRE_NMS_TOPK': 12000,\n",
      "         'UNQUANTIZED_ANCHOR': True},\n",
      " 'TEST': {'BOX_TARGET': 0.377,\n",
      "          'FRCNN_NMS_THRESH': 0.5,\n",
      "          'MASK_TARGET': 0.339,\n",
      "          'RESULTS_PER_IM': 100,\n",
      "          'RESULT_SCORE_THRESH': 0.05,\n",
      "          'RESULT_SCORE_THRESH_VIS': 0.3},\n",
      " 'TRAIN': {'BACKBONE_NCHW': False,\n",
      "           'BASE_LR': 0.00125,\n",
      "           'BATCH_SIZE_PER_GPU': 4,\n",
      "           'EVAL_PERIOD': 24,\n",
      "           'FPN_NCHW': False,\n",
      "           'GRADIENT_CLIP': 0,\n",
      "           'LR_EPOCH_SCHEDULE': [(8, 0.1), (10, 0.01), (12, None)],\n",
      "           'MASK_NCHW': False,\n",
      "           'NUM_GPUS': 1,\n",
      "           'RPN_NCHW': False,\n",
      "           'SEED': 1234,\n",
      "           'SHOULD_STOP': False,\n",
      "           'STARTING_EPOCH': 1,\n",
      "           'WARMUP_INIT_LR': 0.000416666666667,\n",
      "           'WARMUP_STEPS': 1000,\n",
      "           'WEIGHT_DECAY': 0.0001},\n",
      " 'TRAINER': 'horovod'}\n"
     ]
    }
   ],
   "source": [
    "finalize_configs(is_training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.TRAIN.EVAL_PERIOD = 1\n",
    "tf.set_random_seed(cfg.TRAIN.SEED)\n",
    "fix_rng_seed(cfg.TRAIN.SEED*hvd.rank())\n",
    "np.random.seed(cfg.TRAIN.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_per_epoch = 120000\n",
    "images_per_step = cfg.TRAIN.NUM_GPUS * cfg.TRAIN.BATCH_SIZE_PER_GPU\n",
    "steps_per_epoch = images_per_epoch // images_per_step\n",
    "batch_size_lr_factor = images_per_step # The LR is defined for bs=1 and then scaled linearly with the batch size\n",
    "base_lr_adjusted_for_bs = cfg.TRAIN.BASE_LR * batch_size_lr_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup LR schedule is step based\n",
    "warmup_start_step = 0\n",
    "warmup_end_step = cfg.TRAIN.WARMUP_STEPS\n",
    "warmup_start_lr = cfg.TRAIN.WARMUP_INIT_LR*8\n",
    "warmup_end_lr = base_lr_adjusted_for_bs\n",
    "warmup_schedule = [(warmup_start_step, warmup_start_lr), (warmup_end_step, warmup_end_lr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_end_epoch = cfg.TRAIN.WARMUP_STEPS * 1. / steps_per_epoch\n",
    "training_start_epoch = int(warmup_end_epoch + 0.5)\n",
    "lr_schedule = [(training_start_epoch, base_lr_adjusted_for_bs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = None\n",
    "for epoch, scheduled_lr_multiplier in cfg.TRAIN.LR_EPOCH_SCHEDULE:\n",
    "    if scheduled_lr_multiplier is None:\n",
    "        max_epoch = epoch # Training end is indicated by a lr_multiplier of None\n",
    "        break\n",
    "\n",
    "    absolute_lr = base_lr_adjusted_for_bs * scheduled_lr_multiplier\n",
    "    lr_schedule.append((epoch, absolute_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In train dataflow\n",
      "loading annotations into memory...\n",
      "Done (t=17.27s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[0819 15:29:23 @dataset.py:50]\u001b[0m Instances loaded from /workspace/shared_workspace/data/coco/coco/annotations/instances_train2017.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118287/118287 [00:19<00:00, 5964.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0819 15:29:43 @tensorpack_utils.py:349]\u001b[0m Load Load annotations for train2017 finished, time:19.9347sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading roidbs\n",
      "\u001b[32m[0819 15:29:47 @data.py:618]\u001b[0m Filtered 1021 images which contain no non-crowd groudtruth boxes. Total #images for training: 117266\n",
      "Batching roidbs\n",
      "Done batching roidbs\n"
     ]
    }
   ],
   "source": [
    "train_dataflow = get_batch_train_dataflow(cfg.TRAIN.BATCH_SIZE_PER_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = '/workspace/shared_workspace/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    # linear warmup\n",
    "    ScheduledHyperParamSetter(\n",
    "        'learning_rate', warmup_schedule, interp='linear', step_based=True),\n",
    "    ScheduledHyperParamSetter('learning_rate', lr_schedule),\n",
    "    EstimatedTimeLeft(median=True),\n",
    "    SessionRunTimeout(60000).set_chief_only(True),   # 1 minute timeout\n",
    "]\n",
    "'''PeriodicCallback(\n",
    "        ModelSaver(max_to_keep=10, keep_checkpoint_every_n_hours=1),\n",
    "        every_k_epochs=20),\n",
    "        PeakMemoryTracker(),'''\n",
    "\n",
    "callbacks.extend([\n",
    "    EvalCallback(dataset, *MODEL.get_inference_tensor_names(), logdir, 1, a_sync=True) #cfg.TRAIN.BATCH_SIZE_PER_GPU)\n",
    "    for dataset in cfg.DATA.VAL\n",
    "])\n",
    "\n",
    "\n",
    "callbacks.append(ThroughputTracker(cfg.TRAIN.BATCH_SIZE_PER_GPU*cfg.TRAIN.NUM_GPUS,\n",
    "                                   images_per_epoch,\n",
    "                                   trigger_every_n_steps=2000,\n",
    "                                   log_fn=logger.info))\n",
    "\n",
    "# modify profiler callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_init = get_model_loader(cfg.BACKBONE.WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "traincfg = TrainConfig(\n",
    "            model=MODEL,\n",
    "            data=QueueInput(train_dataflow),\n",
    "            callbacks=callbacks,\n",
    "            extra_callbacks=[\n",
    "               MovingAverageSummary(),\n",
    "               ProgressBar(),\n",
    "               MergeAllSummaries(period=250),\n",
    "               RunUpdateOps()\n",
    "            ],\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            max_epoch=max_epoch,\n",
    "            session_init=session_init,\n",
    "            session_config=None,\n",
    "            starting_epoch=cfg.TRAIN.STARTING_EPOCH\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0819 15:29:49 @tensorpack_input_source.py:238]\u001b[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[32m[0819 15:29:49 @tensorpack_models.py:181]\u001b[0m conv0 input: [None, None, None, 3]\n",
      "Use channels_last data format\n",
      "WARNING:tensorflow:From ../MaskRCNN/tensorpack_models.py:448: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:189]\u001b[0m conv0 output: [None, None, None, 64]\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:181]\u001b[0m pool0 input: [None, None, None, 64]\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:189]\u001b[0m pool0 output: [None, None, None, 64]\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:181]\u001b[0m group0/block0/conv1 input: [None, None, None, 64]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:189]\u001b[0m group0/block0/conv1 output: [None, None, None, 64]\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:181]\u001b[0m group0/block0/conv2 input: [None, None, None, 64]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:189]\u001b[0m group0/block0/conv2 output: [None, None, None, 64]\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:181]\u001b[0m group0/block0/conv3 input: [None, None, None, 64]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:189]\u001b[0m group0/block0/conv3 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:181]\u001b[0m group0/block0/convshortcut input: [None, None, None, 64]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:189]\u001b[0m group0/block0/convshortcut output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:181]\u001b[0m group0/block1/conv1 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:189]\u001b[0m group0/block1/conv1 output: [None, None, None, 64]\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:181]\u001b[0m group0/block1/conv2 input: [None, None, None, 64]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:189]\u001b[0m group0/block1/conv2 output: [None, None, None, 64]\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:181]\u001b[0m group0/block1/conv3 input: [None, None, None, 64]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:189]\u001b[0m group0/block1/conv3 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:181]\u001b[0m group0/block2/conv1 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:189]\u001b[0m group0/block2/conv1 output: [None, None, None, 64]\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:181]\u001b[0m group0/block2/conv2 input: [None, None, None, 64]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:189]\u001b[0m group0/block2/conv2 output: [None, None, None, 64]\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:181]\u001b[0m group0/block2/conv3 input: [None, None, None, 64]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:189]\u001b[0m group0/block2/conv3 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:181]\u001b[0m group1/block0/conv1 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:189]\u001b[0m group1/block0/conv1 output: [None, None, None, 128]\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:181]\u001b[0m group1/block0/conv2 input: [None, None, None, 128]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:189]\u001b[0m group1/block0/conv2 output: [None, None, None, 128]\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:181]\u001b[0m group1/block0/conv3 input: [None, None, None, 128]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:189]\u001b[0m group1/block0/conv3 output: [None, None, None, 512]\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:181]\u001b[0m group1/block0/convshortcut input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:189]\u001b[0m group1/block0/convshortcut output: [None, None, None, 512]\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:181]\u001b[0m group1/block1/conv1 input: [None, None, None, 512]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:189]\u001b[0m group1/block1/conv1 output: [None, None, None, 128]\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:181]\u001b[0m group1/block1/conv2 input: [None, None, None, 128]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:189]\u001b[0m group1/block1/conv2 output: [None, None, None, 128]\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:181]\u001b[0m group1/block1/conv3 input: [None, None, None, 128]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:189]\u001b[0m group1/block1/conv3 output: [None, None, None, 512]\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:181]\u001b[0m group1/block2/conv1 input: [None, None, None, 512]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:189]\u001b[0m group1/block2/conv1 output: [None, None, None, 128]\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:181]\u001b[0m group1/block2/conv2 input: [None, None, None, 128]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:189]\u001b[0m group1/block2/conv2 output: [None, None, None, 128]\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:181]\u001b[0m group1/block2/conv3 input: [None, None, None, 128]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:50 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:189]\u001b[0m group1/block2/conv3 output: [None, None, None, 512]\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:181]\u001b[0m group1/block3/conv1 input: [None, None, None, 512]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:189]\u001b[0m group1/block3/conv1 output: [None, None, None, 128]\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:181]\u001b[0m group1/block3/conv2 input: [None, None, None, 128]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:189]\u001b[0m group1/block3/conv2 output: [None, None, None, 128]\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:181]\u001b[0m group1/block3/conv3 input: [None, None, None, 128]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:189]\u001b[0m group1/block3/conv3 output: [None, None, None, 512]\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:181]\u001b[0m group2/block0/conv1 input: [None, None, None, 512]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:189]\u001b[0m group2/block0/conv1 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:181]\u001b[0m group2/block0/conv2 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:189]\u001b[0m group2/block0/conv2 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:181]\u001b[0m group2/block0/conv3 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:189]\u001b[0m group2/block0/conv3 output: [None, None, None, 1024]\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:181]\u001b[0m group2/block0/convshortcut input: [None, None, None, 512]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:189]\u001b[0m group2/block0/convshortcut output: [None, None, None, 1024]\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:181]\u001b[0m group2/block1/conv1 input: [None, None, None, 1024]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:189]\u001b[0m group2/block1/conv1 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:181]\u001b[0m group2/block1/conv2 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:189]\u001b[0m group2/block1/conv2 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:181]\u001b[0m group2/block1/conv3 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:189]\u001b[0m group2/block1/conv3 output: [None, None, None, 1024]\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:181]\u001b[0m group2/block2/conv1 input: [None, None, None, 1024]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:189]\u001b[0m group2/block2/conv1 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:181]\u001b[0m group2/block2/conv2 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:189]\u001b[0m group2/block2/conv2 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:181]\u001b[0m group2/block2/conv3 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:189]\u001b[0m group2/block2/conv3 output: [None, None, None, 1024]\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:181]\u001b[0m group2/block3/conv1 input: [None, None, None, 1024]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:189]\u001b[0m group2/block3/conv1 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:181]\u001b[0m group2/block3/conv2 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:189]\u001b[0m group2/block3/conv2 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:181]\u001b[0m group2/block3/conv3 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:189]\u001b[0m group2/block3/conv3 output: [None, None, None, 1024]\n",
      "\u001b[32m[0819 15:29:51 @tensorpack_models.py:181]\u001b[0m group2/block4/conv1 input: [None, None, None, 1024]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:189]\u001b[0m group2/block4/conv1 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:181]\u001b[0m group2/block4/conv2 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:189]\u001b[0m group2/block4/conv2 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:181]\u001b[0m group2/block4/conv3 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:189]\u001b[0m group2/block4/conv3 output: [None, None, None, 1024]\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:181]\u001b[0m group2/block5/conv1 input: [None, None, None, 1024]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:189]\u001b[0m group2/block5/conv1 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:181]\u001b[0m group2/block5/conv2 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:189]\u001b[0m group2/block5/conv2 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:181]\u001b[0m group2/block5/conv3 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:189]\u001b[0m group2/block5/conv3 output: [None, None, None, 1024]\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:181]\u001b[0m group3/block0/conv1 input: [None, None, None, 1024]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:189]\u001b[0m group3/block0/conv1 output: [None, None, None, 512]\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:181]\u001b[0m group3/block0/conv2 input: [None, None, None, 512]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:189]\u001b[0m group3/block0/conv2 output: [None, None, None, 512]\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:181]\u001b[0m group3/block0/conv3 input: [None, None, None, 512]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:189]\u001b[0m group3/block0/conv3 output: [None, None, None, 2048]\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:181]\u001b[0m group3/block0/convshortcut input: [None, None, None, 1024]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:189]\u001b[0m group3/block0/convshortcut output: [None, None, None, 2048]\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:181]\u001b[0m group3/block1/conv1 input: [None, None, None, 2048]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:189]\u001b[0m group3/block1/conv1 output: [None, None, None, 512]\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:181]\u001b[0m group3/block1/conv2 input: [None, None, None, 512]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:189]\u001b[0m group3/block1/conv2 output: [None, None, None, 512]\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:181]\u001b[0m group3/block1/conv3 input: [None, None, None, 512]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:189]\u001b[0m group3/block1/conv3 output: [None, None, None, 2048]\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:181]\u001b[0m group3/block2/conv1 input: [None, None, None, 2048]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:189]\u001b[0m group3/block2/conv1 output: [None, None, None, 512]\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:181]\u001b[0m group3/block2/conv2 input: [None, None, None, 512]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:52 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:189]\u001b[0m group3/block2/conv2 output: [None, None, None, 512]\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:181]\u001b[0m group3/block2/conv3 input: [None, None, None, 512]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:189]\u001b[0m group3/block2/conv3 output: [None, None, None, 2048]\n",
      "c2345 [<tf.Tensor 'transpose_2:0' shape=(None, 256, None, None) dtype=float16>, <tf.Tensor 'transpose_3:0' shape=(None, 512, None, None) dtype=float16>, <tf.Tensor 'transpose_4:0' shape=(None, 1024, None, None) dtype=float16>, <tf.Tensor 'transpose_5:0' shape=(None, 2048, None, None) dtype=float16>]\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:181]\u001b[0m fpn input: [None, None, None, 256],[None, None, None, 512],[None, None, None, 1024],[None, None, None, 2048]\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:181]\u001b[0m fpn/lateral_1x1_c2 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:189]\u001b[0m fpn/lateral_1x1_c2 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:181]\u001b[0m fpn/lateral_1x1_c3 input: [None, None, None, 512]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:189]\u001b[0m fpn/lateral_1x1_c3 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:181]\u001b[0m fpn/lateral_1x1_c4 input: [None, None, None, 1024]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:189]\u001b[0m fpn/lateral_1x1_c4 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:181]\u001b[0m fpn/lateral_1x1_c5 input: [None, None, None, 2048]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:189]\u001b[0m fpn/lateral_1x1_c5 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:181]\u001b[0m fpn/upsample_lat5 input: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:189]\u001b[0m fpn/upsample_lat5 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:181]\u001b[0m fpn/upsample_lat4 input: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:189]\u001b[0m fpn/upsample_lat4 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:181]\u001b[0m fpn/upsample_lat3 input: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:189]\u001b[0m fpn/upsample_lat3 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:181]\u001b[0m fpn/posthoc_3x3_p2 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:189]\u001b[0m fpn/posthoc_3x3_p2 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:181]\u001b[0m fpn/posthoc_3x3_p3 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:189]\u001b[0m fpn/posthoc_3x3_p3 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:181]\u001b[0m fpn/posthoc_3x3_p4 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:189]\u001b[0m fpn/posthoc_3x3_p4 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:181]\u001b[0m fpn/posthoc_3x3_p5 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:189]\u001b[0m fpn/posthoc_3x3_p5 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:181]\u001b[0m fpn/maxpool_p6 input: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:189]\u001b[0m fpn/maxpool_p6 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:189]\u001b[0m fpn output: [None, None, None, 256],[None, None, None, 256],[None, None, None, 256],[None, None, None, 256],[None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:181]\u001b[0m rpn input: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:181]\u001b[0m rpn/conv0 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:189]\u001b[0m rpn/conv0 output: [None, None, None, 256]\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:181]\u001b[0m rpn/class input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:189]\u001b[0m rpn/class output: [None, None, None, 3]\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:181]\u001b[0m rpn/box input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:189]\u001b[0m rpn/box output: [None, None, None, 12]\n",
      "\u001b[32m[0819 15:29:53 @tensorpack_models.py:189]\u001b[0m rpn output: [None, None, None, 3],[None, 12, None, None]\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:57 @tensorpack_models.py:181]\u001b[0m fastrcnn input: [None, 256, 7, 7]\n",
      "WARNING:tensorflow:From ../MaskRCNN/model/boxclass_head.py:151: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "\u001b[32m[0819 15:29:57 @tensorpack_models.py:181]\u001b[0m fastrcnn/fc6 input: [None, 256, 7, 7]\n",
      "\u001b[32m[0819 15:29:57 @tensorpack_models.py:189]\u001b[0m fastrcnn/fc6 output: [None, 1024]\n",
      "\u001b[32m[0819 15:29:57 @tensorpack_models.py:181]\u001b[0m fastrcnn/fc7 input: [None, 1024]\n",
      "\u001b[32m[0819 15:29:57 @tensorpack_models.py:189]\u001b[0m fastrcnn/fc7 output: [None, 1024]\n",
      "\u001b[32m[0819 15:29:57 @tensorpack_models.py:189]\u001b[0m fastrcnn output: [None, 1024]\n",
      "\u001b[32m[0819 15:29:57 @tensorpack_models.py:181]\u001b[0m fastrcnn/outputs input: [None, 1024]\n",
      "\u001b[32m[0819 15:29:57 @tensorpack_models.py:181]\u001b[0m fastrcnn/outputs/class input: [None, 1024]\n",
      "\u001b[32m[0819 15:29:57 @tensorpack_models.py:189]\u001b[0m fastrcnn/outputs/class output: [None, 81]\n",
      "\u001b[32m[0819 15:29:57 @tensorpack_models.py:181]\u001b[0m fastrcnn/outputs/box input: [None, 1024]\n",
      "\u001b[32m[0819 15:29:57 @tensorpack_models.py:189]\u001b[0m fastrcnn/outputs/box output: [None, 324]\n",
      "\u001b[32m[0819 15:29:57 @tensorpack_models.py:189]\u001b[0m fastrcnn/outputs output: [None, 81],[None, 81, 4]\n",
      "\u001b[32m[0819 15:29:57 @tensorpack_models.py:181]\u001b[0m maskrcnn input: [None, 14, 14, 256]\n",
      "\u001b[32m[0819 15:29:57 @tensorpack_models.py:181]\u001b[0m maskrcnn/fcn0 input: [None, 14, 14, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:57 @tensorpack_models.py:189]\u001b[0m maskrcnn/fcn0 output: [None, 14, 14, 256]\n",
      "\u001b[32m[0819 15:29:57 @tensorpack_models.py:181]\u001b[0m maskrcnn/fcn1 input: [None, 14, 14, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:58 @tensorpack_models.py:189]\u001b[0m maskrcnn/fcn1 output: [None, 14, 14, 256]\n",
      "\u001b[32m[0819 15:29:58 @tensorpack_models.py:181]\u001b[0m maskrcnn/fcn2 input: [None, 14, 14, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:58 @tensorpack_models.py:189]\u001b[0m maskrcnn/fcn2 output: [None, 14, 14, 256]\n",
      "\u001b[32m[0819 15:29:58 @tensorpack_models.py:181]\u001b[0m maskrcnn/fcn3 input: [None, 14, 14, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:58 @tensorpack_models.py:189]\u001b[0m maskrcnn/fcn3 output: [None, 14, 14, 256]\n",
      "\u001b[32m[0819 15:29:58 @tensorpack_models.py:181]\u001b[0m maskrcnn/deconv input: [None, 14, 14, 256]\n",
      "\u001b[32m[0819 15:29:58 @tensorpack_models.py:189]\u001b[0m maskrcnn/deconv output: [None, 28, 28, 256]\n",
      "\u001b[32m[0819 15:29:58 @tensorpack_models.py:181]\u001b[0m maskrcnn/conv input: [None, 28, 28, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0819 15:29:58 @tensorpack_models.py:189]\u001b[0m maskrcnn/conv output: [None, 28, 28, 80]\n",
      "\u001b[32m[0819 15:29:58 @tensorpack_models.py:189]\u001b[0m maskrcnn output: [None, 80, 28, 28]\n",
      "WARNING:tensorflow:From ../MaskRCNN/model_box.py:195: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n",
      "INFO:tensorflow:Summary name mask_truth|pred is illegal; using mask_truth_pred instead.\n",
      "\u001b[32m[0819 15:29:58 @tensorpack_models.py:702]\u001b[0m regularize_cost() found 63 variables to regularize.\n",
      "\u001b[32m[0819 15:29:58 @tensorpack_models.py:636]\u001b[0m The following tensors will be regularized: group1/block0/conv1/W:0, group1/block0/conv2/W:0, group1/block0/conv3/W:0, group1/block0/convshortcut/W:0, group1/block1/conv1/W:0, group1/block1/conv2/W:0, group1/block1/conv3/W:0, group1/block2/conv1/W:0, group1/block2/conv2/W:0, group1/block2/conv3/W:0, group1/block3/conv1/W:0, group1/block3/conv2/W:0, group1/block3/conv3/W:0, group2/block0/conv1/W:0, group2/block0/conv2/W:0, group2/block0/conv3/W:0, group2/block0/convshortcut/W:0, group2/block1/conv1/W:0, group2/block1/conv2/W:0, group2/block1/conv3/W:0, group2/block2/conv1/W:0, group2/block2/conv2/W:0, group2/block2/conv3/W:0, group2/block3/conv1/W:0, group2/block3/conv2/W:0, group2/block3/conv3/W:0, group2/block4/conv1/W:0, group2/block4/conv2/W:0, group2/block4/conv3/W:0, group2/block5/conv1/W:0, group2/block5/conv2/W:0, group2/block5/conv3/W:0, group3/block0/conv1/W:0, group3/block0/conv2/W:0, group3/block0/conv3/W:0, group3/block0/convshortcut/W:0, group3/block1/conv1/W:0, group3/block1/conv2/W:0, group3/block1/conv3/W:0, group3/block2/conv1/W:0, group3/block2/conv2/W:0, group3/block2/conv3/W:0, fpn/lateral_1x1_c2/W:0, fpn/lateral_1x1_c3/W:0, fpn/lateral_1x1_c4/W:0, fpn/lateral_1x1_c5/W:0, fpn/posthoc_3x3_p2/W:0, fpn/posthoc_3x3_p3/W:0, fpn/posthoc_3x3_p4/W:0, fpn/posthoc_3x3_p5/W:0, rpn/conv0/W:0, rpn/class/W:0, rpn/box/W:0, fastrcnn/fc6/W:0, fastrcnn/fc7/W:0, fastrcnn/outputs/class/W:0, fastrcnn/outputs/box/W:0, maskrcnn/fcn0/W:0, maskrcnn/fcn1/W:0, maskrcnn/fcn2/W:0, maskrcnn/fcn3/W:0, maskrcnn/deconv/W:0, maskrcnn/conv/W:0\n",
      "TENSORPACK_FP16 set. Using FP16 loss scaling of 1024.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0819 15:30:06 @tensorpack_interface.py:175]\u001b[0m \u001b[36mTrainable Variables: \n",
      "\u001b[0mname                                   shape                    dim\n",
      "-------------------------------------  ------------------  --------\n",
      "group1/block0/conv1/W:0                [1, 1, 256, 128]       32768\n",
      "group1/block0/conv1/bn/gamma:0         [128]                    128\n",
      "group1/block0/conv1/bn/beta:0          [128]                    128\n",
      "group1/block0/conv2/W:0                [3, 3, 128, 128]      147456\n",
      "group1/block0/conv2/bn/gamma:0         [128]                    128\n",
      "group1/block0/conv2/bn/beta:0          [128]                    128\n",
      "group1/block0/conv3/W:0                [1, 1, 128, 512]       65536\n",
      "group1/block0/conv3/bn/gamma:0         [512]                    512\n",
      "group1/block0/conv3/bn/beta:0          [512]                    512\n",
      "group1/block0/convshortcut/W:0         [1, 1, 256, 512]      131072\n",
      "group1/block0/convshortcut/bn/gamma:0  [512]                    512\n",
      "group1/block0/convshortcut/bn/beta:0   [512]                    512\n",
      "group1/block1/conv1/W:0                [1, 1, 512, 128]       65536\n",
      "group1/block1/conv1/bn/gamma:0         [128]                    128\n",
      "group1/block1/conv1/bn/beta:0          [128]                    128\n",
      "group1/block1/conv2/W:0                [3, 3, 128, 128]      147456\n",
      "group1/block1/conv2/bn/gamma:0         [128]                    128\n",
      "group1/block1/conv2/bn/beta:0          [128]                    128\n",
      "group1/block1/conv3/W:0                [1, 1, 128, 512]       65536\n",
      "group1/block1/conv3/bn/gamma:0         [512]                    512\n",
      "group1/block1/conv3/bn/beta:0          [512]                    512\n",
      "group1/block2/conv1/W:0                [1, 1, 512, 128]       65536\n",
      "group1/block2/conv1/bn/gamma:0         [128]                    128\n",
      "group1/block2/conv1/bn/beta:0          [128]                    128\n",
      "group1/block2/conv2/W:0                [3, 3, 128, 128]      147456\n",
      "group1/block2/conv2/bn/gamma:0         [128]                    128\n",
      "group1/block2/conv2/bn/beta:0          [128]                    128\n",
      "group1/block2/conv3/W:0                [1, 1, 128, 512]       65536\n",
      "group1/block2/conv3/bn/gamma:0         [512]                    512\n",
      "group1/block2/conv3/bn/beta:0          [512]                    512\n",
      "group1/block3/conv1/W:0                [1, 1, 512, 128]       65536\n",
      "group1/block3/conv1/bn/gamma:0         [128]                    128\n",
      "group1/block3/conv1/bn/beta:0          [128]                    128\n",
      "group1/block3/conv2/W:0                [3, 3, 128, 128]      147456\n",
      "group1/block3/conv2/bn/gamma:0         [128]                    128\n",
      "group1/block3/conv2/bn/beta:0          [128]                    128\n",
      "group1/block3/conv3/W:0                [1, 1, 128, 512]       65536\n",
      "group1/block3/conv3/bn/gamma:0         [512]                    512\n",
      "group1/block3/conv3/bn/beta:0          [512]                    512\n",
      "group2/block0/conv1/W:0                [1, 1, 512, 256]      131072\n",
      "group2/block0/conv1/bn/gamma:0         [256]                    256\n",
      "group2/block0/conv1/bn/beta:0          [256]                    256\n",
      "group2/block0/conv2/W:0                [3, 3, 256, 256]      589824\n",
      "group2/block0/conv2/bn/gamma:0         [256]                    256\n",
      "group2/block0/conv2/bn/beta:0          [256]                    256\n",
      "group2/block0/conv3/W:0                [1, 1, 256, 1024]     262144\n",
      "group2/block0/conv3/bn/gamma:0         [1024]                  1024\n",
      "group2/block0/conv3/bn/beta:0          [1024]                  1024\n",
      "group2/block0/convshortcut/W:0         [1, 1, 512, 1024]     524288\n",
      "group2/block0/convshortcut/bn/gamma:0  [1024]                  1024\n",
      "group2/block0/convshortcut/bn/beta:0   [1024]                  1024\n",
      "group2/block1/conv1/W:0                [1, 1, 1024, 256]     262144\n",
      "group2/block1/conv1/bn/gamma:0         [256]                    256\n",
      "group2/block1/conv1/bn/beta:0          [256]                    256\n",
      "group2/block1/conv2/W:0                [3, 3, 256, 256]      589824\n",
      "group2/block1/conv2/bn/gamma:0         [256]                    256\n",
      "group2/block1/conv2/bn/beta:0          [256]                    256\n",
      "group2/block1/conv3/W:0                [1, 1, 256, 1024]     262144\n",
      "group2/block1/conv3/bn/gamma:0         [1024]                  1024\n",
      "group2/block1/conv3/bn/beta:0          [1024]                  1024\n",
      "group2/block2/conv1/W:0                [1, 1, 1024, 256]     262144\n",
      "group2/block2/conv1/bn/gamma:0         [256]                    256\n",
      "group2/block2/conv1/bn/beta:0          [256]                    256\n",
      "group2/block2/conv2/W:0                [3, 3, 256, 256]      589824\n",
      "group2/block2/conv2/bn/gamma:0         [256]                    256\n",
      "group2/block2/conv2/bn/beta:0          [256]                    256\n",
      "group2/block2/conv3/W:0                [1, 1, 256, 1024]     262144\n",
      "group2/block2/conv3/bn/gamma:0         [1024]                  1024\n",
      "group2/block2/conv3/bn/beta:0          [1024]                  1024\n",
      "group2/block3/conv1/W:0                [1, 1, 1024, 256]     262144\n",
      "group2/block3/conv1/bn/gamma:0         [256]                    256\n",
      "group2/block3/conv1/bn/beta:0          [256]                    256\n",
      "group2/block3/conv2/W:0                [3, 3, 256, 256]      589824\n",
      "group2/block3/conv2/bn/gamma:0         [256]                    256\n",
      "group2/block3/conv2/bn/beta:0          [256]                    256\n",
      "group2/block3/conv3/W:0                [1, 1, 256, 1024]     262144\n",
      "group2/block3/conv3/bn/gamma:0         [1024]                  1024\n",
      "group2/block3/conv3/bn/beta:0          [1024]                  1024\n",
      "group2/block4/conv1/W:0                [1, 1, 1024, 256]     262144\n",
      "group2/block4/conv1/bn/gamma:0         [256]                    256\n",
      "group2/block4/conv1/bn/beta:0          [256]                    256\n",
      "group2/block4/conv2/W:0                [3, 3, 256, 256]      589824\n",
      "group2/block4/conv2/bn/gamma:0         [256]                    256\n",
      "group2/block4/conv2/bn/beta:0          [256]                    256\n",
      "group2/block4/conv3/W:0                [1, 1, 256, 1024]     262144\n",
      "group2/block4/conv3/bn/gamma:0         [1024]                  1024\n",
      "group2/block4/conv3/bn/beta:0          [1024]                  1024\n",
      "group2/block5/conv1/W:0                [1, 1, 1024, 256]     262144\n",
      "group2/block5/conv1/bn/gamma:0         [256]                    256\n",
      "group2/block5/conv1/bn/beta:0          [256]                    256\n",
      "group2/block5/conv2/W:0                [3, 3, 256, 256]      589824\n",
      "group2/block5/conv2/bn/gamma:0         [256]                    256\n",
      "group2/block5/conv2/bn/beta:0          [256]                    256\n",
      "group2/block5/conv3/W:0                [1, 1, 256, 1024]     262144\n",
      "group2/block5/conv3/bn/gamma:0         [1024]                  1024\n",
      "group2/block5/conv3/bn/beta:0          [1024]                  1024\n",
      "group3/block0/conv1/W:0                [1, 1, 1024, 512]     524288\n",
      "group3/block0/conv1/bn/gamma:0         [512]                    512\n",
      "group3/block0/conv1/bn/beta:0          [512]                    512\n",
      "group3/block0/conv2/W:0                [3, 3, 512, 512]     2359296\n",
      "group3/block0/conv2/bn/gamma:0         [512]                    512\n",
      "group3/block0/conv2/bn/beta:0          [512]                    512\n",
      "group3/block0/conv3/W:0                [1, 1, 512, 2048]    1048576\n",
      "group3/block0/conv3/bn/gamma:0         [2048]                  2048\n",
      "group3/block0/conv3/bn/beta:0          [2048]                  2048\n",
      "group3/block0/convshortcut/W:0         [1, 1, 1024, 2048]   2097152\n",
      "group3/block0/convshortcut/bn/gamma:0  [2048]                  2048\n",
      "group3/block0/convshortcut/bn/beta:0   [2048]                  2048\n",
      "group3/block1/conv1/W:0                [1, 1, 2048, 512]    1048576\n",
      "group3/block1/conv1/bn/gamma:0         [512]                    512\n",
      "group3/block1/conv1/bn/beta:0          [512]                    512\n",
      "group3/block1/conv2/W:0                [3, 3, 512, 512]     2359296\n",
      "group3/block1/conv2/bn/gamma:0         [512]                    512\n",
      "group3/block1/conv2/bn/beta:0          [512]                    512\n",
      "group3/block1/conv3/W:0                [1, 1, 512, 2048]    1048576\n",
      "group3/block1/conv3/bn/gamma:0         [2048]                  2048\n",
      "group3/block1/conv3/bn/beta:0          [2048]                  2048\n",
      "group3/block2/conv1/W:0                [1, 1, 2048, 512]    1048576\n",
      "group3/block2/conv1/bn/gamma:0         [512]                    512\n",
      "group3/block2/conv1/bn/beta:0          [512]                    512\n",
      "group3/block2/conv2/W:0                [3, 3, 512, 512]     2359296\n",
      "group3/block2/conv2/bn/gamma:0         [512]                    512\n",
      "group3/block2/conv2/bn/beta:0          [512]                    512\n",
      "group3/block2/conv3/W:0                [1, 1, 512, 2048]    1048576\n",
      "group3/block2/conv3/bn/gamma:0         [2048]                  2048\n",
      "group3/block2/conv3/bn/beta:0          [2048]                  2048\n",
      "fpn/lateral_1x1_c2/W:0                 [1, 1, 256, 256]       65536\n",
      "fpn/lateral_1x1_c2/b:0                 [256]                    256\n",
      "fpn/lateral_1x1_c3/W:0                 [1, 1, 512, 256]      131072\n",
      "fpn/lateral_1x1_c3/b:0                 [256]                    256\n",
      "fpn/lateral_1x1_c4/W:0                 [1, 1, 1024, 256]     262144\n",
      "fpn/lateral_1x1_c4/b:0                 [256]                    256\n",
      "fpn/lateral_1x1_c5/W:0                 [1, 1, 2048, 256]     524288\n",
      "fpn/lateral_1x1_c5/b:0                 [256]                    256\n",
      "fpn/posthoc_3x3_p2/W:0                 [3, 3, 256, 256]      589824\n",
      "fpn/posthoc_3x3_p2/b:0                 [256]                    256\n",
      "fpn/posthoc_3x3_p3/W:0                 [3, 3, 256, 256]      589824\n",
      "fpn/posthoc_3x3_p3/b:0                 [256]                    256\n",
      "fpn/posthoc_3x3_p4/W:0                 [3, 3, 256, 256]      589824\n",
      "fpn/posthoc_3x3_p4/b:0                 [256]                    256\n",
      "fpn/posthoc_3x3_p5/W:0                 [3, 3, 256, 256]      589824\n",
      "fpn/posthoc_3x3_p5/b:0                 [256]                    256\n",
      "rpn/conv0/W:0                          [3, 3, 256, 256]      589824\n",
      "rpn/conv0/b:0                          [256]                    256\n",
      "rpn/class/W:0                          [1, 1, 256, 3]           768\n",
      "rpn/class/b:0                          [3]                        3\n",
      "rpn/box/W:0                            [1, 1, 256, 12]         3072\n",
      "rpn/box/b:0                            [12]                      12\n",
      "fastrcnn/fc6/W:0                       [12544, 1024]       12845056\n",
      "fastrcnn/fc6/b:0                       [1024]                  1024\n",
      "fastrcnn/fc7/W:0                       [1024, 1024]         1048576\n",
      "fastrcnn/fc7/b:0                       [1024]                  1024\n",
      "fastrcnn/outputs/class/W:0             [1024, 81]             82944\n",
      "fastrcnn/outputs/class/b:0             [81]                      81\n",
      "fastrcnn/outputs/box/W:0               [1024, 324]           331776\n",
      "fastrcnn/outputs/box/b:0               [324]                    324\n",
      "maskrcnn/fcn0/W:0                      [3, 3, 256, 256]      589824\n",
      "maskrcnn/fcn0/b:0                      [256]                    256\n",
      "maskrcnn/fcn1/W:0                      [3, 3, 256, 256]      589824\n",
      "maskrcnn/fcn1/b:0                      [256]                    256\n",
      "maskrcnn/fcn2/W:0                      [3, 3, 256, 256]      589824\n",
      "maskrcnn/fcn2/b:0                      [256]                    256\n",
      "maskrcnn/fcn3/W:0                      [3, 3, 256, 256]      589824\n",
      "maskrcnn/fcn3/b:0                      [256]                    256\n",
      "maskrcnn/deconv/W:0                    [2, 2, 256, 256]      262144\n",
      "maskrcnn/deconv/b:0                    [256]                    256\n",
      "maskrcnn/conv/W:0                      [1, 1, 256, 80]        20480\n",
      "maskrcnn/conv/b:0                      [80]                      80\u001b[36m\n",
      "Total #vars=168, #params=44175092, size=168.51MB\u001b[0m\n",
      "\u001b[32m[0819 15:30:06 @tensorpack_callbacks.py:1130]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m logger directory was not set. Ignore TFEventWriter.\n",
      "\u001b[32m[0819 15:30:06 @tensorpack_callbacks.py:1454]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m logger directory was not set. Ignore JSONWriter.\n",
      "\u001b[32m[0819 15:30:06 @tensorpack_interface.py:256]\u001b[0m Setup callbacks graph ...\n",
      "\u001b[32m[0819 15:30:06 @eval.py:482]\u001b[0m Building pred graph on device /gpu:0...\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "c2345 [<tf.Tensor 'pred-0/transpose_2:0' shape=(None, 256, None, None) dtype=float16>, <tf.Tensor 'pred-0/transpose_3:0' shape=(None, 512, None, None) dtype=float16>, <tf.Tensor 'pred-0/transpose_4:0' shape=(None, 1024, None, None) dtype=float16>, <tf.Tensor 'pred-0/transpose_5:0' shape=(None, 2048, None, None) dtype=float16>]\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "loading annotations into memory...\n",
      "Done (t=1.87s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[0819 15:30:17 @dataset.py:50]\u001b[0m Instances loaded from /workspace/shared_workspace/data/coco/coco/annotations/instances_val2017.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 152324.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0819 15:30:17 @tensorpack_utils.py:349]\u001b[0m Load Load annotations for val2017 finished, time:0.0481sec.\n",
      "\u001b[32m[0819 15:30:17 @tensorpack_callbacks.py:1586]\u001b[0m [MovingAverageSummary] 27 operations in collection 'MOVING_SUMMARY_OPS' will be run with session hooks.\n",
      "\u001b[32m[0819 15:30:17 @tensorpack_callbacks.py:1632]\u001b[0m Summarizing collection 'summaries' of size 30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0819 15:30:21 @tensorpack_interface.py:325]\u001b[0m Creating the session ...\n",
      "\u001b[32m[0819 15:30:35 @tensorpack_interface.py:342]\u001b[0m Initializing the session ...\n",
      "\u001b[32m[0819 15:30:35 @tensorpack_tfutils.py:891]\u001b[0m Variables to restore from dict: group0/block1/conv3/bn/variance/EMA:0, group1/block3/conv2/bn/variance/EMA:0, group0/block0/conv2/bn/beta:0, group2/block0/conv2/bn/mean/EMA:0, group2/block1/conv1/bn/beta:0, group2/block2/conv1/bn/gamma:0, group1/block0/conv3/bn/gamma:0, group1/block1/conv3/bn/gamma:0, group0/block2/conv1/bn/mean/EMA:0, group2/block4/conv2/bn/mean/EMA:0, group2/block0/conv3/bn/variance/EMA:0, group1/block3/conv1/bn/beta:0, group1/block0/conv3/bn/beta:0, group3/block0/convshortcut/bn/variance/EMA:0, group0/block0/conv2/W:0, group1/block2/conv3/bn/mean/EMA:0, group3/block2/conv2/bn/variance/EMA:0, group2/block0/conv2/bn/gamma:0, group0/block1/conv3/bn/gamma:0, group0/block1/conv1/W:0, group0/block2/conv1/bn/variance/EMA:0, group1/block3/conv1/bn/mean/EMA:0, group0/block0/conv1/bn/variance/EMA:0, group2/block4/conv3/W:0, group2/block5/conv3/bn/mean/EMA:0, group2/block0/convshortcut/bn/gamma:0, group3/block2/conv3/bn/mean/EMA:0, group2/block4/conv1/W:0, group2/block4/conv1/bn/mean/EMA:0, group0/block2/conv2/bn/gamma:0, group0/block1/conv2/W:0, group0/block2/conv1/bn/beta:0, group2/block2/conv2/bn/variance/EMA:0, group1/block2/conv2/bn/mean/EMA:0, group1/block0/conv2/bn/mean/EMA:0, group3/block1/conv1/bn/variance/EMA:0, group2/block1/conv1/W:0, group2/block2/conv2/bn/mean/EMA:0, group2/block2/conv3/W:0, group1/block0/convshortcut/bn/beta:0, group2/block2/conv3/bn/mean/EMA:0, group3/block2/conv2/bn/mean/EMA:0, group0/block0/conv2/bn/mean/EMA:0, group2/block0/conv1/W:0, group2/block0/conv1/bn/variance/EMA:0, group2/block2/conv3/bn/gamma:0, group1/block2/conv3/bn/beta:0, group2/block4/conv2/bn/variance/EMA:0, group3/block2/conv1/bn/mean/EMA:0, group1/block0/conv3/W:0, group2/block1/conv2/W:0, conv0/bn/gamma:0, group2/block3/conv2/bn/gamma:0, group3/block0/conv3/W:0, group0/block1/conv1/bn/beta:0, group2/block1/conv3/bn/gamma:0, group0/block2/conv3/bn/mean/EMA:0, group1/block1/conv1/bn/gamma:0, group2/block2/conv1/bn/beta:0, group2/block3/conv3/bn/beta:0, group0/block0/conv3/bn/variance/EMA:0, group0/block0/conv1/bn/gamma:0, group2/block4/conv3/bn/variance/EMA:0, group3/block0/convshortcut/bn/gamma:0, group0/block0/convshortcut/bn/beta:0, group2/block5/conv1/W:0, group1/block1/conv2/W:0, group1/block0/conv1/W:0, group1/block3/conv2/bn/mean/EMA:0, group2/block5/conv3/W:0, group2/block4/conv1/bn/beta:0, group3/block0/conv2/bn/variance/EMA:0, group2/block3/conv1/bn/gamma:0, group0/block0/conv1/bn/mean/EMA:0, group1/block2/conv1/W:0, group1/block2/conv1/bn/variance/EMA:0, group1/block0/convshortcut/W:0, group3/block0/conv3/bn/beta:0, group3/block1/conv1/W:0, group3/block0/conv1/W:0, group0/block1/conv3/bn/beta:0, group3/block0/convshortcut/bn/mean/EMA:0, group1/block0/convshortcut/bn/mean/EMA:0, conv0/bn/mean/EMA:0, group2/block0/conv1/bn/beta:0, group2/block4/conv3/bn/gamma:0, group3/block0/conv2/bn/gamma:0, group0/block1/conv2/bn/mean/EMA:0, group2/block3/conv2/bn/beta:0, group0/block1/conv2/bn/gamma:0, group1/block3/conv2/bn/gamma:0, group2/block2/conv3/bn/beta:0, group2/block3/conv3/bn/gamma:0, group1/block2/conv2/bn/beta:0, group1/block1/conv3/bn/beta:0, group1/block3/conv3/bn/gamma:0, group1/block0/conv2/bn/gamma:0, group1/block1/conv2/bn/gamma:0, group2/block0/convshortcut/bn/variance/EMA:0, group2/block4/conv1/bn/variance/EMA:0, group1/block0/conv2/W:0, group3/block1/conv2/bn/gamma:0, group0/block1/conv3/bn/mean/EMA:0, group2/block3/conv3/bn/variance/EMA:0, group1/block2/conv1/bn/mean/EMA:0, group3/block1/conv1/bn/mean/EMA:0, group1/block2/conv3/bn/variance/EMA:0, group2/block1/conv1/bn/gamma:0, group1/block2/conv2/W:0, group2/block1/conv3/bn/variance/EMA:0, group1/block1/conv2/bn/beta:0, group3/block1/conv2/W:0, group3/block2/conv2/bn/gamma:0, group0/block0/convshortcut/bn/gamma:0, group0/block1/conv1/bn/variance/EMA:0, group1/block2/conv2/bn/gamma:0, group3/block2/conv1/bn/beta:0, group0/block0/conv1/W:0, conv0/W:0, group2/block0/conv2/W:0, group1/block0/conv2/bn/variance/EMA:0, group1/block1/conv2/bn/variance/EMA:0, group1/block3/conv2/bn/beta:0, group2/block5/conv3/bn/variance/EMA:0, group1/block2/conv3/bn/gamma:0, group1/block0/convshortcut/bn/gamma:0, group2/block1/conv1/bn/mean/EMA:0, group3/block0/convshortcut/bn/beta:0, group2/block3/conv2/bn/mean/EMA:0, group2/block1/conv2/bn/beta:0, group1/block0/conv1/bn/mean/EMA:0, group2/block0/conv3/bn/beta:0, group2/block3/conv2/W:0, group2/block1/conv3/bn/mean/EMA:0, group1/block1/conv3/bn/variance/EMA:0, group2/block0/conv3/W:0, group2/block3/conv2/bn/variance/EMA:0, group3/block0/conv2/W:0, group2/block5/conv2/bn/mean/EMA:0, group2/block4/conv2/bn/gamma:0, group2/block0/conv1/bn/mean/EMA:0, group0/block2/conv3/bn/variance/EMA:0, group3/block2/conv3/bn/beta:0, group0/block0/conv2/bn/gamma:0, group0/block0/convshortcut/W:0, group2/block0/conv2/bn/variance/EMA:0, group2/block3/conv1/bn/mean/EMA:0, group1/block3/conv1/bn/gamma:0, group3/block2/conv2/W:0, group1/block0/conv2/bn/beta:0, group1/block2/conv3/W:0, group2/block5/conv1/bn/beta:0, group2/block3/conv1/bn/beta:0, group3/block0/conv1/bn/gamma:0, group3/block1/conv1/bn/gamma:0, group2/block1/conv2/bn/mean/EMA:0, group2/block2/conv2/bn/gamma:0, group2/block0/conv1/bn/gamma:0, group0/block2/conv1/bn/gamma:0, group3/block1/conv2/bn/mean/EMA:0, group0/block0/conv3/W:0, group0/block1/conv1/bn/mean/EMA:0, group2/block5/conv3/bn/gamma:0, group2/block5/conv2/bn/gamma:0, group0/block0/conv1/bn/beta:0, group1/block1/conv3/bn/mean/EMA:0, group0/block0/conv3/bn/mean/EMA:0, group0/block0/convshortcut/bn/variance/EMA:0, group2/block3/conv1/bn/variance/EMA:0, group2/block4/conv2/W:0, group0/block2/conv2/bn/variance/EMA:0, group3/block1/conv2/bn/variance/EMA:0, group3/block0/conv3/bn/variance/EMA:0, group1/block1/conv3/W:0, group1/block3/conv1/bn/variance/EMA:0, group1/block2/conv1/bn/beta:0, group3/block0/convshortcut/W:0, group2/block5/conv2/W:0, group3/block2/conv3/W:0, group2/block4/conv2/bn/beta:0, group2/block0/conv3/bn/mean/EMA:0, group3/block2/conv2/bn/beta:0, group0/block2/conv1/W:0, group2/block0/conv2/bn/beta:0, group0/block0/conv3/bn/gamma:0, group1/block1/conv1/bn/variance/EMA:0, group1/block0/conv3/bn/mean/EMA:0, group2/block2/conv2/W:0, group2/block2/conv1/bn/variance/EMA:0, group2/block2/conv1/bn/mean/EMA:0, group2/block3/conv1/W:0, group0/block0/conv3/bn/beta:0, group1/block1/conv2/bn/mean/EMA:0, group2/block4/conv1/bn/gamma:0, group3/block0/conv2/bn/beta:0, group1/block1/conv1/bn/mean/EMA:0, group0/block2/conv2/W:0, group0/block1/conv2/bn/variance/EMA:0, group3/block1/conv2/bn/beta:0, group0/block2/conv2/bn/beta:0, group2/block5/conv1/bn/mean/EMA:0, group1/block3/conv3/bn/variance/EMA:0, group1/block3/conv2/W:0, conv0/bn/variance/EMA:0, group0/block2/conv3/bn/beta:0, group2/block0/convshortcut/W:0, group2/block1/conv2/bn/variance/EMA:0, group3/block0/conv1/bn/variance/EMA:0, group2/block5/conv2/bn/variance/EMA:0, group3/block0/conv2/bn/mean/EMA:0, group3/block0/conv1/bn/mean/EMA:0, group2/block4/conv3/bn/beta:0, group1/block3/conv3/bn/mean/EMA:0, group1/block0/convshortcut/bn/variance/EMA:0, group3/block2/conv3/bn/variance/EMA:0, group2/block1/conv1/bn/variance/EMA:0, group0/block1/conv2/bn/beta:0, group0/block1/conv3/W:0, group0/block1/conv1/bn/gamma:0, group2/block0/convshortcut/bn/beta:0, group3/block1/conv3/bn/beta:0, group3/block2/conv1/bn/variance/EMA:0, group3/block1/conv1/bn/beta:0, group2/block1/conv3/bn/beta:0, group1/block0/conv1/bn/beta:0, group0/block2/conv2/bn/mean/EMA:0, group0/block0/conv2/bn/variance/EMA:0, group0/block2/conv3/W:0, group0/block2/conv3/bn/gamma:0, group3/block0/conv1/bn/beta:0, group2/block2/conv1/W:0, group2/block3/conv3/bn/mean/EMA:0, group1/block3/conv3/W:0, group3/block1/conv3/bn/gamma:0, group3/block0/conv3/bn/mean/EMA:0, group1/block0/conv3/bn/variance/EMA:0, group1/block2/conv2/bn/variance/EMA:0, group2/block1/conv3/W:0, group2/block2/conv2/bn/beta:0, group2/block0/convshortcut/bn/mean/EMA:0, group2/block5/conv1/bn/gamma:0, group1/block1/conv1/bn/beta:0, group1/block0/conv1/bn/variance/EMA:0, group3/block1/conv3/bn/variance/EMA:0, group3/block2/conv1/W:0, group2/block5/conv2/bn/beta:0, group1/block1/conv1/W:0, group1/block3/conv3/bn/beta:0, group2/block4/conv3/bn/mean/EMA:0, group2/block3/conv3/W:0, group2/block5/conv1/bn/variance/EMA:0, group1/block3/conv1/W:0, group2/block2/conv3/bn/variance/EMA:0, group3/block2/conv3/bn/gamma:0, group1/block0/conv1/bn/gamma:0, group2/block0/conv3/bn/gamma:0, group3/block0/conv3/bn/gamma:0, group3/block2/conv1/bn/gamma:0, group3/block1/conv3/bn/mean/EMA:0, group0/block0/convshortcut/bn/mean/EMA:0, group3/block1/conv3/W:0, conv0/bn/beta:0, group2/block1/conv2/bn/gamma:0, group1/block2/conv1/bn/gamma:0, group2/block5/conv3/bn/beta:0\n",
      "\u001b[32m[0819 15:30:35 @tensorpack_tfutils.py:604]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The following variables are in the graph, but not found in the dict: current_loss_scale, fastrcnn/fc6/W, fastrcnn/fc6/b, fastrcnn/fc7/W, fastrcnn/fc7/b, fastrcnn/outputs/box/W, fastrcnn/outputs/box/b, fastrcnn/outputs/class/W, fastrcnn/outputs/class/b, fpn/lateral_1x1_c2/W, fpn/lateral_1x1_c2/b, fpn/lateral_1x1_c3/W, fpn/lateral_1x1_c3/b, fpn/lateral_1x1_c4/W, fpn/lateral_1x1_c4/b, fpn/lateral_1x1_c5/W, fpn/lateral_1x1_c5/b, fpn/posthoc_3x3_p2/W, fpn/posthoc_3x3_p2/b, fpn/posthoc_3x3_p3/W, fpn/posthoc_3x3_p3/b, fpn/posthoc_3x3_p4/W, fpn/posthoc_3x3_p4/b, fpn/posthoc_3x3_p5/W, fpn/posthoc_3x3_p5/b, global_step, good_steps, learning_rate, maskrcnn/conv/W, maskrcnn/conv/b, maskrcnn/deconv/W, maskrcnn/deconv/b, maskrcnn/fcn0/W, maskrcnn/fcn0/b, maskrcnn/fcn1/W, maskrcnn/fcn1/b, maskrcnn/fcn2/W, maskrcnn/fcn2/b, maskrcnn/fcn3/W, maskrcnn/fcn3/b, rpn/box/W, rpn/box/b, rpn/class/W, rpn/class/b, rpn/conv0/W, rpn/conv0/b\n",
      "\u001b[32m[0819 15:30:35 @tensorpack_tfutils.py:604]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m The following variables are in the dict, but not found in the graph: linear/W, linear/b\n",
      "\u001b[32m[0819 15:30:35 @tensorpack_tfutils.py:904]\u001b[0m Restoring 265 variables from dict ...\n",
      "WARNING:tensorflow:From ../MaskRCNN/tensorpack_tfutils.py:751: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "\u001b[32m[0819 15:31:33 @tensorpack_tfutils.py:747]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Variable group0/block0/convshortcut/W has dtype <dtype: 'float16'> but was given a value of dtype float32. Load it after downcasting!\n",
      "\u001b[32m[0819 15:31:34 @tensorpack_tfutils.py:747]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Variable group0/block1/conv2/W has dtype <dtype: 'float16'> but was given a value of dtype float32. Load it after downcasting!\n",
      "\u001b[32m[0819 15:32:05 @tensorpack_tfutils.py:747]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Variable group0/block2/conv3/W has dtype <dtype: 'float16'> but was given a value of dtype float32. Load it after downcasting!\n",
      "\u001b[32m[0819 15:32:22 @tensorpack_tfutils.py:747]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Variable group0/block0/conv2/W has dtype <dtype: 'float16'> but was given a value of dtype float32. Load it after downcasting!\n",
      "\u001b[32m[0819 15:32:25 @tensorpack_tfutils.py:747]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Variable conv0/W has dtype <dtype: 'float16'> but was given a value of dtype float32. Load it after downcasting!\n",
      "\u001b[32m[0819 15:32:29 @tensorpack_tfutils.py:747]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Variable group0/block0/conv1/W has dtype <dtype: 'float16'> but was given a value of dtype float32. Load it after downcasting!\n",
      "\u001b[32m[0819 15:32:46 @tensorpack_tfutils.py:747]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Variable group0/block2/conv1/W has dtype <dtype: 'float16'> but was given a value of dtype float32. Load it after downcasting!\n",
      "\u001b[32m[0819 15:33:17 @tensorpack_tfutils.py:747]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Variable group0/block0/conv3/W has dtype <dtype: 'float16'> but was given a value of dtype float32. Load it after downcasting!\n",
      "\u001b[32m[0819 15:34:03 @tensorpack_tfutils.py:747]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Variable group0/block1/conv3/W has dtype <dtype: 'float16'> but was given a value of dtype float32. Load it after downcasting!\n",
      "\u001b[32m[0819 15:34:15 @tensorpack_tfutils.py:747]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Variable group0/block2/conv2/W has dtype <dtype: 'float16'> but was given a value of dtype float32. Load it after downcasting!\n",
      "\u001b[32m[0819 15:35:29 @tensorpack_tfutils.py:747]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m Variable group0/block1/conv1/W has dtype <dtype: 'float16'> but was given a value of dtype float32. Load it after downcasting!\n",
      "\u001b[32m[0819 15:36:54 @tensorpack_interface.py:349]\u001b[0m Graph Finalized.\n",
      "\u001b[32m[0819 15:36:54 @tensorpack_interface.py:352]\u001b[0m Broadcasting initialized variables ...\n",
      "\u001b[32m[0819 15:36:56 @tensorpack_callbacks.py:1359]\u001b[0m Starting EnqueueThread QueueInput/input_queue ...\n",
      "\u001b[32m[0819 15:36:56 @tensorpack_callbacks.py:598]\u001b[0m [HyperParamSetter] At global_step=0, learning_rate is set to 0.003333\n",
      "\u001b[32m[0819 15:36:57 @tensorpack_callbacks.py:598]\u001b[0m [HyperParamSetter] At global_step=0, learning_rate is set to 0.005000\n",
      "\u001b[32m[0819 15:36:57 @eval.py:499]\u001b[0m [EvalCallback] Will evaluate every 1 epochs\n",
      "\u001b[32m[0819 15:36:57 @tensorpack_interface.py:444]\u001b[0m Start Epoch 1 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          |0/30000[00:00<?,?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0819 15:37:18 @tensorpack_callbacks.py:601]\u001b[0m [HyperParamSetter] At global_step=1, learning_rate changes from 0.003333 to 0.003335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|1         |321/30000[02:16<2:36:07, 3.17it/s] "
     ]
    }
   ],
   "source": [
    "launch_train_with_config(traincfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
