{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../MaskRCNN/')\n",
    "import itertools\n",
    "import numpy as np\n",
    "import shutil\n",
    "import cv2\n",
    "import six\n",
    "assert six.PY3, \"FasterRCNN requires Python 3!\"\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "import tqdm\n",
    "import time\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "import tensorpack_viz as tpviz\n",
    "from tensorpack_tfutils import get_tf_version_tuple, get_model_loader\n",
    "from tensorpack_utils import fix_rng_seed\n",
    "from tensorpack_input_source import QueueInput\n",
    "from tensorpack_train import TrainConfig\n",
    "from tensorpack_interface import launch_train_with_config\n",
    "from tensorpack_callbacks import PeriodicCallback, EnableCallbackIf, ModelSaver,\\\n",
    "                                 GraphProfiler, PeakMemoryTracker, EstimatedTimeLeft, SessionRunTimeout, \\\n",
    "                                 MovingAverageSummary, ProgressBar, MergeAllSummaries, RunUpdateOps, ScheduledHyperParamSetter\n",
    "import tensorpack_logger as logger\n",
    "\n",
    "\n",
    "from dataset import DetectionDataset\n",
    "from config import finalize_configs, config as cfg\n",
    "from data import get_eval_dataflow, get_train_dataflow, get_batch_train_dataflow\n",
    "from eval import DetectionResult, predict_image, multithread_predict_dataflow, EvalCallback\n",
    "from viz import draw_annotation, draw_final_outputs, draw_predictions, draw_proposal_recall\n",
    "from performance import ThroughputTracker, humanize_float\n",
    "from model.generalized_rcnn import ResNetFPNModel\n",
    "import horovod.tensorflow as hvd\n",
    "\n",
    "config = ['MODE_MASK=True',\n",
    "'MODE_FPN=True',\n",
    "'DATA.BASEDIR=/workspace/shared_workspace/data/coco/coco/',\n",
    "'DATA.TRAIN=[\"train2017\"]',\n",
    "'DATA.VAL=(\"val2017\",)',\n",
    "'TRAIN.BATCH_SIZE_PER_GPU=4',\n",
    "'TRAIN.LR_EPOCH_SCHEDULE=[(8, 0.1), (10, 0.01), (12, None)]',\n",
    "'TRAIN.EVAL_PERIOD=24',\n",
    "'TRAIN.BACKBONE_NCHW=False',\n",
    "'TRAIN.FPN_NCHW=False',\n",
    "'TRAIN.RPN_NCHW=False',\n",
    "'TRAIN.MASK_NCHW=False',\n",
    "'RPN.TOPK_PER_IMAGE=True',\n",
    "'PREPROC.PREDEFINED_PADDING=False',\n",
    "'BACKBONE.WEIGHTS=/workspace/shared_workspace/data/coco/pretrained-models/ImageNet-R50-AlignPadding.npz',\n",
    "'BACKBONE.NORM=FreezeBN',\n",
    "'TRAIN.WARMUP_INIT_LR=0.000416666666667',\n",
    "'FRCNN.BBOX_REG_WEIGHTS=[20., 20., 10., 10.]',\n",
    "'TRAINER=horovod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.update_args(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = ResNetFPNModel(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dataset.DetectionDataset at 0x7f9594d90b00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DetectionDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_horovod = cfg.TRAINER == 'horovod'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hvd.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0818 13:31:42 @config.py:264]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m It's not recommended to use horovod for single-machine training. Replicated trainer is more stable and has the same efficiency.\n",
      "\u001b[32m[0818 13:31:42 @config.py:285]\u001b[0m Config: ------------------------------------------\n",
      "{'BACKBONE': {'FREEZE_AFFINE': False,\n",
      "              'FREEZE_AT': 2,\n",
      "              'NORM': 'FreezeBN',\n",
      "              'RESNET_NUM_BLOCKS': [3, 4, 6, 3],\n",
      "              'STRIDE_1X1': False,\n",
      "              'TF_PAD_MODE': False,\n",
      "              'WEIGHTS': '/workspace/shared_workspace/data/coco/pretrained-models/ImageNet-R50-AlignPadding.npz'},\n",
      " 'DATA': {'BASEDIR': '/workspace/shared_workspace/data/coco/coco/',\n",
      "          'CLASS_NAMES': ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
      "                          'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
      "                          'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
      "                          'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag',\n",
      "                          'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite',\n",
      "                          'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
      "                          'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon',\n",
      "                          'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot',\n",
      "                          'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant',\n",
      "                          'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
      "                          'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',\n",
      "                          'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
      "                          'hair drier', 'toothbrush'],\n",
      "          'NUM_CATEGORY': 80,\n",
      "          'NUM_CLASS': 81,\n",
      "          'TRAIN': ['train2017'],\n",
      "          'VAL': ('val2017',)},\n",
      " 'FPN': {'ANCHOR_STRIDES': (4, 8, 16, 32, 64),\n",
      "         'BOXCLASS_CONV_HEAD_DIM': 256,\n",
      "         'BOXCLASS_FC_HEAD_DIM': 1024,\n",
      "         'BOXCLASS_HEAD_FUNC': 'boxclass_2fc_head',\n",
      "         'MRCNN_HEAD_FUNC': 'maskrcnn_up4conv_head',\n",
      "         'NORM': 'None',\n",
      "         'NUM_CHANNEL': 256,\n",
      "         'PROPOSAL_MODE': 'Level',\n",
      "         'RESOLUTION_REQUIREMENT': 32},\n",
      " 'FRCNN': {'BATCH_PER_IM': 512,\n",
      "           'BBOX_REG_WEIGHTS': [20.0, 20.0, 10.0, 10.0],\n",
      "           'FG_RATIO': 0.25,\n",
      "           'FG_THRESH': 0.5},\n",
      " 'MODE_FPN': True,\n",
      " 'MODE_MASK': True,\n",
      " 'MRCNN': {'HEAD_DIM': 256},\n",
      " 'PREPROC': {'MAX_SIZE': 1344.0,\n",
      "             'PADDING_SHAPES': [(800, 1000), (800, 1200), (800, 1350)],\n",
      "             'PIXEL_MEAN': [123.675, 116.28, 103.53],\n",
      "             'PIXEL_STD': [58.395, 57.12, 57.375],\n",
      "             'PREDEFINED_PADDING': False,\n",
      "             'TEST_SHORT_EDGE_SIZE': 800,\n",
      "             'TRAIN_SHORT_EDGE_SIZE': [800, 800]},\n",
      " 'RPN': {'ANCHOR_RATIOS': (0.5, 1.0, 2.0),\n",
      "         'ANCHOR_SIZES': (32, 64, 128, 256, 512),\n",
      "         'ANCHOR_STRIDE': 16,\n",
      "         'BATCH_PER_IM': 256,\n",
      "         'CROWD_OVERLAP_THRESH': 9.99,\n",
      "         'FG_RATIO': 0.5,\n",
      "         'HEAD_DIM': 1024,\n",
      "         'MIN_SIZE': 0.1,\n",
      "         'NEGATIVE_ANCHOR_THRESH': 0.3,\n",
      "         'NUM_ANCHOR': 15,\n",
      "         'POSITIVE_ANCHOR_THRESH': 0.7,\n",
      "         'PROPOSAL_NMS_THRESH': 0.7,\n",
      "         'SLOW_ACCURATE_MASK': True,\n",
      "         'TEST_PER_LEVEL_NMS_TOPK': 1000,\n",
      "         'TEST_POST_NMS_TOPK': 1000,\n",
      "         'TEST_PRE_NMS_TOPK': 6000,\n",
      "         'TOPK_PER_IMAGE': True,\n",
      "         'TRAIN_PER_LEVEL_NMS_TOPK': 2000,\n",
      "         'TRAIN_POST_NMS_TOPK': 2000,\n",
      "         'TRAIN_PRE_NMS_TOPK': 12000,\n",
      "         'UNQUANTIZED_ANCHOR': True},\n",
      " 'TEST': {'BOX_TARGET': 0.377,\n",
      "          'FRCNN_NMS_THRESH': 0.5,\n",
      "          'MASK_TARGET': 0.339,\n",
      "          'RESULTS_PER_IM': 100,\n",
      "          'RESULT_SCORE_THRESH': 0.05,\n",
      "          'RESULT_SCORE_THRESH_VIS': 0.3},\n",
      " 'TRAIN': {'BACKBONE_NCHW': False,\n",
      "           'BASE_LR': 0.00125,\n",
      "           'BATCH_SIZE_PER_GPU': 4,\n",
      "           'EVAL_PERIOD': 24,\n",
      "           'FPN_NCHW': False,\n",
      "           'GRADIENT_CLIP': 0,\n",
      "           'LR_EPOCH_SCHEDULE': [(8, 0.1), (10, 0.01), (12, None)],\n",
      "           'MASK_NCHW': False,\n",
      "           'NUM_GPUS': 1,\n",
      "           'RPN_NCHW': False,\n",
      "           'SEED': 1234,\n",
      "           'SHOULD_STOP': False,\n",
      "           'STARTING_EPOCH': 1,\n",
      "           'WARMUP_INIT_LR': 0.000416666666667,\n",
      "           'WARMUP_STEPS': 1000,\n",
      "           'WEIGHT_DECAY': 0.0001},\n",
      " 'TRAINER': 'horovod'}\n"
     ]
    }
   ],
   "source": [
    "finalize_configs(is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.TRAIN.EVAL_PERIOD = 1\n",
    "tf.set_random_seed(cfg.TRAIN.SEED)\n",
    "fix_rng_seed(cfg.TRAIN.SEED*hvd.rank())\n",
    "np.random.seed(cfg.TRAIN.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_per_epoch = 120000\n",
    "images_per_step = cfg.TRAIN.NUM_GPUS * cfg.TRAIN.BATCH_SIZE_PER_GPU\n",
    "steps_per_epoch = images_per_epoch // images_per_step\n",
    "batch_size_lr_factor = images_per_step # The LR is defined for bs=1 and then scaled linearly with the batch size\n",
    "base_lr_adjusted_for_bs = cfg.TRAIN.BASE_LR * batch_size_lr_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup LR schedule is step based\n",
    "warmup_start_step = 0\n",
    "warmup_end_step = cfg.TRAIN.WARMUP_STEPS\n",
    "warmup_start_lr = cfg.TRAIN.WARMUP_INIT_LR*8\n",
    "warmup_end_lr = base_lr_adjusted_for_bs\n",
    "warmup_schedule = [(warmup_start_step, warmup_start_lr), (warmup_end_step, warmup_end_lr)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_end_epoch = cfg.TRAIN.WARMUP_STEPS * 1. / steps_per_epoch\n",
    "training_start_epoch = int(warmup_end_epoch + 0.5)\n",
    "lr_schedule = [(training_start_epoch, base_lr_adjusted_for_bs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = None\n",
    "for epoch, scheduled_lr_multiplier in cfg.TRAIN.LR_EPOCH_SCHEDULE:\n",
    "    if scheduled_lr_multiplier is None:\n",
    "        max_epoch = epoch # Training end is indicated by a lr_multiplier of None\n",
    "        break\n",
    "\n",
    "    absolute_lr = base_lr_adjusted_for_bs * scheduled_lr_multiplier\n",
    "    lr_schedule.append((epoch, absolute_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In train dataflow\n",
      "loading annotations into memory...\n",
      "Done (t=14.65s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[0818 13:31:58 @dataset.py:50]\u001b[0m Instances loaded from /workspace/shared_workspace/data/coco/coco/annotations/instances_train2017.json.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118287/118287 [00:17<00:00, 6953.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0818 13:32:15 @tensorpack_utils.py:349]\u001b[0m Load Load annotations for train2017 finished, time:17.0964sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done loading roidbs\n",
      "\u001b[32m[0818 13:32:18 @data.py:618]\u001b[0m Filtered 1021 images which contain no non-crowd groudtruth boxes. Total #images for training: 117266\n",
      "Batching roidbs\n",
      "Done batching roidbs\n"
     ]
    }
   ],
   "source": [
    "train_dataflow = get_batch_train_dataflow(cfg.TRAIN.BATCH_SIZE_PER_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = '/workspace/shared_workspace/logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    PeriodicCallback(\n",
    "        ModelSaver(max_to_keep=10, keep_checkpoint_every_n_hours=1),\n",
    "        every_k_epochs=20),\n",
    "    # linear warmup\n",
    "    ScheduledHyperParamSetter(\n",
    "        'learning_rate', warmup_schedule, interp='linear', step_based=True),\n",
    "    ScheduledHyperParamSetter('learning_rate', lr_schedule),\n",
    "    PeakMemoryTracker(),\n",
    "    EstimatedTimeLeft(median=True),\n",
    "    SessionRunTimeout(60000).set_chief_only(True),   # 1 minute timeout\n",
    "]\n",
    "\n",
    "callbacks.extend([\n",
    "    EvalCallback(dataset, *MODEL.get_inference_tensor_names(), logdir, 1, a_sync=True) #cfg.TRAIN.BATCH_SIZE_PER_GPU)\n",
    "    for dataset in cfg.DATA.VAL\n",
    "])\n",
    "\n",
    "\n",
    "callbacks.append(ThroughputTracker(cfg.TRAIN.BATCH_SIZE_PER_GPU*cfg.TRAIN.NUM_GPUS,\n",
    "                                   images_per_epoch,\n",
    "                                   trigger_every_n_steps=2000,\n",
    "                                   log_fn=logger.info))\n",
    "\n",
    "# modify profiler callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_init = get_model_loader(cfg.BACKBONE.WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "traincfg = TrainConfig(\n",
    "            model=MODEL,\n",
    "            data=QueueInput(train_dataflow),\n",
    "            callbacks=callbacks,\n",
    "            extra_callbacks=[\n",
    "               MovingAverageSummary(),\n",
    "               ProgressBar(),\n",
    "               MergeAllSummaries(period=250),\n",
    "               RunUpdateOps()\n",
    "            ],\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            max_epoch=max_epoch,\n",
    "            session_init=session_init,\n",
    "            session_config=None,\n",
    "            starting_epoch=cfg.TRAIN.STARTING_EPOCH\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[0818 13:32:19 @tensorpack_input_source.py:238]\u001b[0m Setting up the queue 'QueueInput/input_queue' for CPU prefetching ...\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "\u001b[32m[0818 13:32:19 @tensorpack_models.py:181]\u001b[0m conv0 input: [None, None, None, 3]\n",
      "Use channels_last data format\n",
      "WARNING:tensorflow:From ../MaskRCNN/tensorpack_models.py:448: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "\u001b[32m[0818 13:32:19 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:19 @tensorpack_models.py:189]\u001b[0m conv0 output: [None, None, None, 64]\n",
      "\u001b[32m[0818 13:32:19 @tensorpack_models.py:181]\u001b[0m pool0 input: [None, None, None, 64]\n",
      "\u001b[32m[0818 13:32:19 @tensorpack_models.py:189]\u001b[0m pool0 output: [None, None, None, 64]\n",
      "\u001b[32m[0818 13:32:19 @tensorpack_models.py:181]\u001b[0m group0/block0/conv1 input: [None, None, None, 64]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:19 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:19 @tensorpack_models.py:189]\u001b[0m group0/block0/conv1 output: [None, None, None, 64]\n",
      "\u001b[32m[0818 13:32:19 @tensorpack_models.py:181]\u001b[0m group0/block0/conv2 input: [None, None, None, 64]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:19 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:19 @tensorpack_models.py:189]\u001b[0m group0/block0/conv2 output: [None, None, None, 64]\n",
      "\u001b[32m[0818 13:32:19 @tensorpack_models.py:181]\u001b[0m group0/block0/conv3 input: [None, None, None, 64]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:19 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:189]\u001b[0m group0/block0/conv3 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:181]\u001b[0m group0/block0/convshortcut input: [None, None, None, 64]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:189]\u001b[0m group0/block0/convshortcut output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:181]\u001b[0m group0/block1/conv1 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:189]\u001b[0m group0/block1/conv1 output: [None, None, None, 64]\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:181]\u001b[0m group0/block1/conv2 input: [None, None, None, 64]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:189]\u001b[0m group0/block1/conv2 output: [None, None, None, 64]\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:181]\u001b[0m group0/block1/conv3 input: [None, None, None, 64]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:189]\u001b[0m group0/block1/conv3 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:181]\u001b[0m group0/block2/conv1 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:189]\u001b[0m group0/block2/conv1 output: [None, None, None, 64]\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:181]\u001b[0m group0/block2/conv2 input: [None, None, None, 64]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:189]\u001b[0m group0/block2/conv2 output: [None, None, None, 64]\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:181]\u001b[0m group0/block2/conv3 input: [None, None, None, 64]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:189]\u001b[0m group0/block2/conv3 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:181]\u001b[0m group1/block0/conv1 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:189]\u001b[0m group1/block0/conv1 output: [None, None, None, 128]\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:181]\u001b[0m group1/block0/conv2 input: [None, None, None, 128]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:189]\u001b[0m group1/block0/conv2 output: [None, None, None, 128]\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:181]\u001b[0m group1/block0/conv3 input: [None, None, None, 128]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:189]\u001b[0m group1/block0/conv3 output: [None, None, None, 512]\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:181]\u001b[0m group1/block0/convshortcut input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:189]\u001b[0m group1/block0/convshortcut output: [None, None, None, 512]\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:181]\u001b[0m group1/block1/conv1 input: [None, None, None, 512]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:189]\u001b[0m group1/block1/conv1 output: [None, None, None, 128]\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:181]\u001b[0m group1/block1/conv2 input: [None, None, None, 128]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:189]\u001b[0m group1/block1/conv2 output: [None, None, None, 128]\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:181]\u001b[0m group1/block1/conv3 input: [None, None, None, 128]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:189]\u001b[0m group1/block1/conv3 output: [None, None, None, 512]\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:181]\u001b[0m group1/block2/conv1 input: [None, None, None, 512]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:189]\u001b[0m group1/block2/conv1 output: [None, None, None, 128]\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:181]\u001b[0m group1/block2/conv2 input: [None, None, None, 128]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:189]\u001b[0m group1/block2/conv2 output: [None, None, None, 128]\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:181]\u001b[0m group1/block2/conv3 input: [None, None, None, 128]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:189]\u001b[0m group1/block2/conv3 output: [None, None, None, 512]\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:181]\u001b[0m group1/block3/conv1 input: [None, None, None, 512]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:189]\u001b[0m group1/block3/conv1 output: [None, None, None, 128]\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:181]\u001b[0m group1/block3/conv2 input: [None, None, None, 128]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:189]\u001b[0m group1/block3/conv2 output: [None, None, None, 128]\n",
      "\u001b[32m[0818 13:32:20 @tensorpack_models.py:181]\u001b[0m group1/block3/conv3 input: [None, None, None, 128]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:189]\u001b[0m group1/block3/conv3 output: [None, None, None, 512]\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:181]\u001b[0m group2/block0/conv1 input: [None, None, None, 512]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:189]\u001b[0m group2/block0/conv1 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:181]\u001b[0m group2/block0/conv2 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:189]\u001b[0m group2/block0/conv2 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:181]\u001b[0m group2/block0/conv3 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:189]\u001b[0m group2/block0/conv3 output: [None, None, None, 1024]\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:181]\u001b[0m group2/block0/convshortcut input: [None, None, None, 512]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:189]\u001b[0m group2/block0/convshortcut output: [None, None, None, 1024]\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:181]\u001b[0m group2/block1/conv1 input: [None, None, None, 1024]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:189]\u001b[0m group2/block1/conv1 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:181]\u001b[0m group2/block1/conv2 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:189]\u001b[0m group2/block1/conv2 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:181]\u001b[0m group2/block1/conv3 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:189]\u001b[0m group2/block1/conv3 output: [None, None, None, 1024]\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:181]\u001b[0m group2/block2/conv1 input: [None, None, None, 1024]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:189]\u001b[0m group2/block2/conv1 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:181]\u001b[0m group2/block2/conv2 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:189]\u001b[0m group2/block2/conv2 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:181]\u001b[0m group2/block2/conv3 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:189]\u001b[0m group2/block2/conv3 output: [None, None, None, 1024]\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:181]\u001b[0m group2/block3/conv1 input: [None, None, None, 1024]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:189]\u001b[0m group2/block3/conv1 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:181]\u001b[0m group2/block3/conv2 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:189]\u001b[0m group2/block3/conv2 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:181]\u001b[0m group2/block3/conv3 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:189]\u001b[0m group2/block3/conv3 output: [None, None, None, 1024]\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:181]\u001b[0m group2/block4/conv1 input: [None, None, None, 1024]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:189]\u001b[0m group2/block4/conv1 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:181]\u001b[0m group2/block4/conv2 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:189]\u001b[0m group2/block4/conv2 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:181]\u001b[0m group2/block4/conv3 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:21 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:189]\u001b[0m group2/block4/conv3 output: [None, None, None, 1024]\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:181]\u001b[0m group2/block5/conv1 input: [None, None, None, 1024]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:189]\u001b[0m group2/block5/conv1 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:181]\u001b[0m group2/block5/conv2 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:189]\u001b[0m group2/block5/conv2 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:181]\u001b[0m group2/block5/conv3 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:189]\u001b[0m group2/block5/conv3 output: [None, None, None, 1024]\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:181]\u001b[0m group3/block0/conv1 input: [None, None, None, 1024]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:189]\u001b[0m group3/block0/conv1 output: [None, None, None, 512]\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:181]\u001b[0m group3/block0/conv2 input: [None, None, None, 512]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:189]\u001b[0m group3/block0/conv2 output: [None, None, None, 512]\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:181]\u001b[0m group3/block0/conv3 input: [None, None, None, 512]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:189]\u001b[0m group3/block0/conv3 output: [None, None, None, 2048]\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:181]\u001b[0m group3/block0/convshortcut input: [None, None, None, 1024]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:189]\u001b[0m group3/block0/convshortcut output: [None, None, None, 2048]\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:181]\u001b[0m group3/block1/conv1 input: [None, None, None, 2048]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:189]\u001b[0m group3/block1/conv1 output: [None, None, None, 512]\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:181]\u001b[0m group3/block1/conv2 input: [None, None, None, 512]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:189]\u001b[0m group3/block1/conv2 output: [None, None, None, 512]\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:181]\u001b[0m group3/block1/conv3 input: [None, None, None, 512]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:189]\u001b[0m group3/block1/conv3 output: [None, None, None, 2048]\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:181]\u001b[0m group3/block2/conv1 input: [None, None, None, 2048]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:189]\u001b[0m group3/block2/conv1 output: [None, None, None, 512]\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:181]\u001b[0m group3/block2/conv2 input: [None, None, None, 512]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:189]\u001b[0m group3/block2/conv2 output: [None, None, None, 512]\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:181]\u001b[0m group3/block2/conv3 input: [None, None, None, 512]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:855]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m [BatchNorm] Using moving_mean/moving_variance in training.\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:189]\u001b[0m group3/block2/conv3 output: [None, None, None, 2048]\n",
      "c2345 [<tf.Tensor 'transpose_2:0' shape=(None, 256, None, None) dtype=float16>, <tf.Tensor 'transpose_3:0' shape=(None, 512, None, None) dtype=float16>, <tf.Tensor 'transpose_4:0' shape=(None, 1024, None, None) dtype=float16>, <tf.Tensor 'transpose_5:0' shape=(None, 2048, None, None) dtype=float16>]\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:181]\u001b[0m fpn input: [None, None, None, 256],[None, None, None, 512],[None, None, None, 1024],[None, None, None, 2048]\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:181]\u001b[0m fpn/lateral_1x1_c2 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:189]\u001b[0m fpn/lateral_1x1_c2 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:22 @tensorpack_models.py:181]\u001b[0m fpn/lateral_1x1_c3 input: [None, None, None, 512]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:189]\u001b[0m fpn/lateral_1x1_c3 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:181]\u001b[0m fpn/lateral_1x1_c4 input: [None, None, None, 1024]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:189]\u001b[0m fpn/lateral_1x1_c4 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:181]\u001b[0m fpn/lateral_1x1_c5 input: [None, None, None, 2048]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:189]\u001b[0m fpn/lateral_1x1_c5 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:181]\u001b[0m fpn/upsample_lat5 input: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:189]\u001b[0m fpn/upsample_lat5 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:181]\u001b[0m fpn/upsample_lat4 input: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:189]\u001b[0m fpn/upsample_lat4 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:181]\u001b[0m fpn/upsample_lat3 input: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:189]\u001b[0m fpn/upsample_lat3 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:181]\u001b[0m fpn/posthoc_3x3_p2 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:189]\u001b[0m fpn/posthoc_3x3_p2 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:181]\u001b[0m fpn/posthoc_3x3_p3 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:189]\u001b[0m fpn/posthoc_3x3_p3 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:181]\u001b[0m fpn/posthoc_3x3_p4 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:189]\u001b[0m fpn/posthoc_3x3_p4 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:181]\u001b[0m fpn/posthoc_3x3_p5 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:189]\u001b[0m fpn/posthoc_3x3_p5 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:181]\u001b[0m fpn/maxpool_p6 input: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:189]\u001b[0m fpn/maxpool_p6 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:189]\u001b[0m fpn output: [None, None, None, 256],[None, None, None, 256],[None, None, None, 256],[None, None, None, 256],[None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:181]\u001b[0m rpn input: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:181]\u001b[0m rpn/conv0 input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:189]\u001b[0m rpn/conv0 output: [None, None, None, 256]\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:181]\u001b[0m rpn/class input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:189]\u001b[0m rpn/class output: [None, None, None, 3]\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:181]\u001b[0m rpn/box input: [None, None, None, 256]\n",
      "Use channels_last data format\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:189]\u001b[0m rpn/box output: [None, None, None, 12]\n",
      "\u001b[32m[0818 13:32:23 @tensorpack_models.py:189]\u001b[0m rpn output: [None, None, None, 3],[None, 12, None, None]\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n",
      "Use channels_last data format\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 3 but is rank 2 for '{{node generate_fpn_proposals_topk_per_image/Lvl0/GenerateBoundingBoxProposals}} = GenerateBoundingBoxProposals[post_nms_topn=2000](generate_fpn_proposals_topk_per_image/Lvl0/strided_slice_1, generate_fpn_proposals_topk_per_image/Lvl0/transpose, generate_fpn_proposals_topk_per_image/Lvl0/Pad, generate_fpn_proposals_topk_per_image/Lvl0/Reshape, generate_fpn_proposals_topk_per_image/Lvl0/GenerateBoundingBoxProposals/nms_threshold, generate_fpn_proposals_topk_per_image/Lvl0/GenerateBoundingBoxProposals/pre_nms_topn, generate_fpn_proposals_topk_per_image/Lvl0/GenerateBoundingBoxProposals/min_size)' with input shapes: [?,?,?,3], [?,?,?,12], [?,5], [338688,4], [], [], [].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1653\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1654\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1655\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape must be rank 3 but is rank 2 for '{{node generate_fpn_proposals_topk_per_image/Lvl0/GenerateBoundingBoxProposals}} = GenerateBoundingBoxProposals[post_nms_topn=2000](generate_fpn_proposals_topk_per_image/Lvl0/strided_slice_1, generate_fpn_proposals_topk_per_image/Lvl0/transpose, generate_fpn_proposals_topk_per_image/Lvl0/Pad, generate_fpn_proposals_topk_per_image/Lvl0/Reshape, generate_fpn_proposals_topk_per_image/Lvl0/GenerateBoundingBoxProposals/nms_threshold, generate_fpn_proposals_topk_per_image/Lvl0/GenerateBoundingBoxProposals/pre_nms_topn, generate_fpn_proposals_topk_per_image/Lvl0/GenerateBoundingBoxProposals/min_size)' with input shapes: [?,?,?,3], [?,?,?,12], [?,5], [338688,4], [], [], [].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-19c507578893>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlaunch_train_with_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraincfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/workspace/shared_workspace/tensorpack/mask-rcnn-tensorflow/MaskRCNN/tensorpack_interface.py\u001b[0m in \u001b[0;36mlaunch_train_with_config\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;31m# Setup graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTrainContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_get_grad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_build_graph_get_cost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_opt_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mallreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/shared_workspace/tensorpack/mask-rcnn-tensorflow/MaskRCNN/tensorpack_interface.py\u001b[0m in \u001b[0;36mget_grad_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mXLA_COMPILE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcompute_grad_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/shared_workspace/tensorpack/mask-rcnn-tensorflow/MaskRCNN/tensorpack_interface.py\u001b[0m in \u001b[0;36mcompute_grad_from_inputs\u001b[0;34m(*inputs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_grad_from_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cost_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cost must be a scalar, but found {}!\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/shared_workspace/tensorpack/mask-rcnn-tensorflow/MaskRCNN/tensorpack_graph_builder.py\u001b[0m in \u001b[0;36m_build_graph_get_cost\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mUsed\u001b[0m \u001b[0minternally\u001b[0m \u001b[0mby\u001b[0m \u001b[0mtrainers\u001b[0m \u001b[0mto\u001b[0m \u001b[0mget\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfinal\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0moptimization\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcompatible\u001b[0m \u001b[0mway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \"\"\"\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mget_current_tower_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m     \u001b[0;31m# this is the tower function, could be called for inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/shared_workspace/tensorpack/mask-rcnn-tensorflow/MaskRCNN/model/generalized_rcnn.py\u001b[0m in \u001b[0;36mbuild_graph\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0manchor_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'anchor_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mproposal_boxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrpn_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchor_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'orig_image_dims'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_gen\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# inputs?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'gt_boxes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gt_labels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gt_masks'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/shared_workspace/tensorpack/mask-rcnn-tensorflow/MaskRCNN/model/generalized_rcnn.py\u001b[0m in \u001b[0;36mrpn\u001b[0;34m(self, image, features, inputs, orig_image_dims, seed_gen)\u001b[0m\n\u001b[1;32m    216\u001b[0m                                                                                     \u001b[0mmultilevel_label_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                                                                                     \u001b[0mimage_shape2d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                                                                                     cfg.TRAIN.BATCH_SIZE_PER_GPU)\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/shared_workspace/tensorpack/mask-rcnn-tensorflow/MaskRCNN/tensorpack_tfutils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscopename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_impl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/shared_workspace/tensorpack/mask-rcnn-tensorflow/MaskRCNN/model/rpn.py\u001b[0m in \u001b[0;36mgenerate_fpn_proposals_topk_per_image\u001b[0;34m(multilevel_anchor_boxes, multilevel_box_logits, multilevel_label_logits, orig_image_dims, batch_size)\u001b[0m\n\u001b[1;32m    311\u001b[0m                                                                              \u001b[0mpre_nms_topn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfpn_nms_topk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                                                                              \u001b[0mmin_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRPN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMIN_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m                                                                              post_nms_topn=fpn_nms_topk)\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                     \u001b[0;31m# rois_probs = print_runtime_shape(f'rois_probs, lvl {lvl}', rois_probs, prefix=bug_prefix)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36mgenerate_bounding_box_proposals\u001b[0;34m(scores, bbox_deltas, image_info, anchors, nms_threshold, pre_nms_topn, min_size, post_nms_topn, name)\u001b[0m\n\u001b[1;32m   4440\u001b[0m       \u001b[0mmin_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4441\u001b[0m       \u001b[0mpost_nms_topn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpost_nms_topn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4442\u001b[0;31m       name=name)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_image_ops.py\u001b[0m in \u001b[0;36mgenerate_bounding_box_proposals\u001b[0;34m(scores, bbox_deltas, image_info, anchors, nms_threshold, pre_nms_topn, min_size, post_nms_topn, name)\u001b[0m\n\u001b[1;32m   1957\u001b[0m                                         \u001b[0mmin_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1958\u001b[0m                                         \u001b[0mpost_nms_topn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpost_nms_topn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m                                         name=name)\n\u001b[0m\u001b[1;32m   1960\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1961\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    742\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    743\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3325\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3326\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3327\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3328\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3329\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0;32m-> 1817\u001b[0;31m                                 control_input_ops, op_def)\n\u001b[0m\u001b[1;32m   1818\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1655\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 3 but is rank 2 for '{{node generate_fpn_proposals_topk_per_image/Lvl0/GenerateBoundingBoxProposals}} = GenerateBoundingBoxProposals[post_nms_topn=2000](generate_fpn_proposals_topk_per_image/Lvl0/strided_slice_1, generate_fpn_proposals_topk_per_image/Lvl0/transpose, generate_fpn_proposals_topk_per_image/Lvl0/Pad, generate_fpn_proposals_topk_per_image/Lvl0/Reshape, generate_fpn_proposals_topk_per_image/Lvl0/GenerateBoundingBoxProposals/nms_threshold, generate_fpn_proposals_topk_per_image/Lvl0/GenerateBoundingBoxProposals/pre_nms_topn, generate_fpn_proposals_topk_per_image/Lvl0/GenerateBoundingBoxProposals/min_size)' with input shapes: [?,?,?,3], [?,?,?,12], [?,5], [338688,4], [], [], []."
     ]
    }
   ],
   "source": [
    "launch_train_with_config(traincfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
